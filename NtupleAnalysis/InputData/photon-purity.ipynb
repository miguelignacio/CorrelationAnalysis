{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.15/01\n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "import csv\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "#import astroML.density_estimation as aml\n",
    "#import astroML.plotting as amlplot\n",
    "import iminuit\n",
    "import pandas as pd\n",
    "import root_pandas as rpd\n",
    "from root_pandas import read_root\n",
    "\n",
    "import ROOT\n",
    "\n",
    "mpl.rcParams.update({'font.size': 16})\n",
    "mpl.rcParams.update({'legend.fontsize': 20})\n",
    "mpl.rcParams.update({'xtick.labelsize': 16}) \n",
    "mpl.rcParams.update({'ytick.labelsize': 16}) \n",
    "mpl.rcParams.update({'text.usetex' : False})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from Ntuples\n",
    "## Get dataframes from TTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getData(inputFiles):\n",
    "    maxEvents = 5000000\n",
    "    \n",
    "    columns = []\n",
    "    columns.append('ncluster')\n",
    "    columns.append('ntrack')\n",
    "\n",
    "    columns.append('run_number')\n",
    "    columns.append('centrality_v0m')\n",
    "    columns.append('eg_cross_section')\n",
    "    columns.append('eg_ntrial')\n",
    "    columns.append('time_stamp')\n",
    "    columns.append('primary_vertex_ncontributor')\n",
    "    columns.append('primary_vertex_spd_ncontributor')\n",
    "    columns.append('npileup_vertex_spd')\n",
    "    columns.append('bunch_crossing_number')\n",
    "    columns.append('is_pileup_from_spd_3_08')\n",
    "    columns.append('is_pileup_from_spd_5_08')\n",
    "    columns.append('ue_estimate_its_const')\n",
    "    columns.append('ue_estimate_tpc_const')\n",
    "\n",
    "    columns_to_flatten = []\n",
    "    columns_to_flatten.append('cluster_pt')\n",
    "    columns_to_flatten.append('cluster_eta')\n",
    "    columns_to_flatten.append('cluster_phi')\n",
    "    columns_to_flatten.append('cluster_e_cross')\n",
    "    columns_to_flatten.append('cluster_e')\n",
    "    columns_to_flatten.append('cluster_e_max')\n",
    "    columns_to_flatten.append('cluster_tof')\n",
    "    columns_to_flatten.append('cluster_ncell')\n",
    "    columns_to_flatten.append('cluster_iso_its_04')\n",
    "    columns_to_flatten.append('cluster_iso_its_04_ue')\n",
    "    columns_to_flatten.append('cluster_iso_tpc_04')\n",
    "    columns_to_flatten.append('cluster_iso_cluster_04')\n",
    "    \n",
    "    columns_to_flatten.append('cluster_iso_its_03')\n",
    "    columns_to_flatten.append('cluster_iso_its_03_ue')\n",
    "    columns_to_flatten.append('cluster_iso_04_truth')\n",
    "    columns_to_flatten.append('cluster_isoetaband_its')\n",
    "    columns_to_flatten.append('cluster_iso_its_new')\n",
    "    columns_to_flatten.append('cluster_frixione_its_04_02')\n",
    "    columns_to_flatten.append('cluster_nlocal_maxima')\n",
    "    columns_to_flatten.append('cluster_NN1')\n",
    "    columns_to_flatten.append('cluster_Lambda')\n",
    "    columns_to_flatten.append('cluster_Lambda_angle')\n",
    "    columns_to_flatten.append('cluster_SuperModule')\n",
    "    columns_to_flatten.append('cluster_isHardPhoton')\n",
    "    columns_to_flatten.append('cluster_distance_to_bad_channel')\n",
    "    \n",
    "    columns = columns + columns_to_flatten\n",
    "    \n",
    "    dataframes = []\n",
    "    for inputFilename in inputFiles:\n",
    "        start = time.time()\n",
    "        df = read_root(inputFilename, columns=columns,flatten=columns_to_flatten)\n",
    "        dataframes.append(df)\n",
    "        end = time.time()\n",
    "        print 'Processed', inputFilename, 'in',  end-start, 'seconds'\n",
    "    return pd.concat([x for x in dataframes])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #start = time.time()\n",
    "    #dataframe = rpd.read_root(inputFiles, columns=columns, flatten=True, stop=maxEvents)\n",
    "    #end = time.time()\n",
    "    #print 'Processed', ','.join(inputFiles), 'in', end-start, 'seconds'\n",
    "    #    \n",
    "    #return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cuts and generate cut flow plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCut(inputDataframe, cut, text=None):\n",
    "    nbeforecut = inputDataframe.shape[0]\n",
    "    cutDataframe = inputDataframe.query(cut)\n",
    "    if text:\n",
    "        print text, cutDataframe.shape[0], ' (%2.2f '%(100.0*cutDataframe.shape[0]/nbeforecut), '%)'\n",
    "    return cutDataframe\n",
    "\n",
    "def applyCuts(fullDataframe,name='default',isMC=False): \n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    mpl.rcParams['legend.fontsize'] = 8\n",
    "    mpl.rcParams['font.size'] = 12\n",
    "    mpl.rcParams['xtick.labelsize']=10 \n",
    "    mpl.rcParams['axes.labelsize'] = 10\n",
    "\n",
    "    fullDataframe.eval('cluster_ecross_over_e = cluster_e_cross/cluster_e', inplace=True)\n",
    "         \n",
    "    if('17g6a1_pt1' in name):\n",
    "        fullDataframe.eval('weights = 1.60e-11', inplace=True)\n",
    "    elif('17g6a1_pt2' in name):\n",
    "        fullDataframe.eval('weights = 2.72e-12', inplace=True)\n",
    "    elif('17g6a1_pt3' in name):\n",
    "        fullDataframe.eval('weights = 3.96e-13', inplace=True)\n",
    "    elif('17g6a1_pt4' in name):\n",
    "        fullDataframe.eval('weights = 6.14e-14', inplace=True)\n",
    "    elif('17g6a1_pt5' in name):\n",
    "        fullDataframe.eval('weights = 1.27e-14', inplace=True)\n",
    "    \n",
    "    elif('17g6a3_pthat1' in name):\n",
    "        fullDataframe.eval('weights = 4.47e-11', inplace=True)\n",
    "    elif('17g6a3_pthat2' in name):\n",
    "        fullDataframe.eval('weights = 9.83e-11', inplace=True)\n",
    "    elif('17g6a3_pthat3' in name):\n",
    "        fullDataframe.eval('weights = 1.04e-10', inplace=True)\n",
    "    elif('17g6a3_pthat4' in name):\n",
    "        fullDataframe.eval('weights = 1.01e-10', inplace=True)\n",
    "    elif('17g6a3_pthat5' in name):\n",
    "        fullDataframe.eval('weights = 6.93e-11', inplace=True)    \n",
    "    \n",
    "    elif('18b11' in name):\n",
    "        fullDataframe.eval('weights = 1', inplace=True)\n",
    "    elif(isMC and ('17g6' not in name)):       \n",
    "        avg_eg_ntrial = str(np.mean(fullDataframe['eg_ntrial']))\n",
    "        fullDataframe.eval('weights=eg_cross_section/'+avg_eg_ntrial, inplace=True)\n",
    "    \n",
    "    if(not isMC):\n",
    "        fullDataframe.eval('weights = 1', inplace=True)\n",
    "    fullDataframe.eval('cluster_emax_over_e = cluster_e_max/cluster_e', inplace=True)\n",
    "  \n",
    "    fullDataframe.eval('cluster_iso_truth = cluster_iso_04_truth', inplace=True)\n",
    "\n",
    "    fullDataframe.eval('cluster_iso_its_04_raw = cluster_iso_its_04+cluster_iso_its_04_ue', inplace=True)\n",
    "    fullDataframe.eval('cluster_iso_its_04_sub = cluster_iso_its_04+cluster_iso_its_04_ue - ue_estimate_its_const*0.4*0.4*3.1416', inplace =True)\n",
    "    fullDataframe.eval('cluster_Lambda_Angle = 1.62*cluster_Lambda_angle', inplace=True)\n",
    "    \n",
    "    fullDataframe.eval('cluster_iso_its_03_raw = cluster_iso_its_03+cluster_iso_its_03_ue', inplace=True)\n",
    "    fullDataframe.eval('cluster_iso_its_04_etaband = cluster_iso_its_04_raw- cluster_isoetaband_its*0.4*0.4*3.14/0.889', inplace=True)\n",
    "\n",
    "    dataframe = fullDataframe\n",
    "    \n",
    "    #if('17g6a1' in name):  \n",
    "    #    dataframe = applyCut(dataframe, 'cluster_iso_truth<5.0', 'cluster_iso_truth<5.0 :')\n",
    "    \n",
    "    dataframe[\"time_stamp\"]= pd.to_datetime(dataframe['time_stamp'],unit='s',errors='coerce')\n",
    "\n",
    "    if('13' in name):\n",
    "        plt.title('p-Pb data',fontsize=16)\n",
    "    elif('17' in name):\n",
    "        plt.title('pp data',fontsize=16)\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.hist(dataframe['cluster_pt'],bins=48, range=(12.0,60.0),color='black',histtype='step', \n",
    "             normed=True,weights=dataframe['weights'])\n",
    "    dataframe = applyCut(dataframe, 'cluster_pt>12.0', 'pt >12.0  GeV/c :')\n",
    "    dataframe = applyCut(dataframe, 'cluster_pt<100.0', 'pt <100.0  GeV/c :')\n",
    "    plt.axvline(x=12.0,color='r',alpha=0.7)\n",
    "    plt.axvline(x=30.0,color='r', alpha=0.7)\n",
    "    plt.xlabel(r'cluster $p_{T}$ [GeV/c]')\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    \n",
    "    dataframe = applyCut(dataframe, 'abs(cluster_eta)<0.67', '|eta| < 0.67 :')\n",
    "\n",
    "    \n",
    "    plt.subplot(2,3,2)\n",
    "    plt.hist(dataframe['cluster_ncell'],range=(0,30), bins=30,color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    dataframe = applyCut(dataframe, 'cluster_ncell>2', 'ncell > 2:')\n",
    "    plt.xlabel('Number of cells in cluster')\n",
    "    plt.axvline(x=4.0,color='r',alpha=0.7)\n",
    "    \n",
    "    \n",
    "    plt.subplot(2,3,3)\n",
    "    plt.hist(dataframe['cluster_ecross_over_e'],bins=100,color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    dataframe = applyCut(dataframe, 'cluster_ecross_over_e>0.05', 'ecross/e > 0.05 :')\n",
    "    plt.axvline(x=0.05,color='r',alpha=0.7)\n",
    "    plt.xlabel(r'$E_{cross}/E_{cluster}$')\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    " \n",
    "    #plt.subplot(2,3,3)\n",
    "    #plt.hist(dataframe['cluster_distance_to_bad_channel'], bins=10,  range=(0,10), color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    #plt.xlabel('Distance to bad channel')\n",
    "    #plt.axvline(x=2.0,color='r',alpha=0.7)\n",
    "    #dataframe = applyCut(dataframe, 'cluster_distance_to_bad_channel>=3.0', 'Distance to bad channel >= 2.0 :')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.hist(dataframe['cluster_tof'], bins=100, range=(-100,100), color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    plt.xlabel('cluster time [ns]')\n",
    "\n",
    "\n",
    "    if (not isMC) : \n",
    "        if( not('17q' in name)):\n",
    "            dataframe = applyCut(dataframe, 'abs(cluster_tof)<20.0', '|cluster time| < 20 [ns]')\n",
    "            plt.axvline(x=20.0,color='r',alpha=0.7)\n",
    "            plt.axvline(x=-20.0,color='r',alpha=0.7)\n",
    "    \n",
    "    \n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.hist(dataframe['cluster_nlocal_maxima'], bins=7,  range=(-0.5,6.5), color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    plt.axvline(x=2.5,color='r',alpha=0.7)\n",
    "    plt.xlabel('Number of local maxima')  \n",
    "    dataframe = applyCut(dataframe, 'cluster_nlocal_maxima<3', 'Local Maxima < 3 :')\n",
    "    \n",
    "    #dataframe = applyCut(dataframe, 'cluster_NN1>0.02', 'cluster_NN1>0.02')\n",
    "    #dataframe = applyCut(dataframe, 'cluster_Lambda_Angle>0.1', 'cluster_lambda >0.1')\n",
    "    #dataframe = applyCut(dataframe, 'cluster_Lambda_Angle<2.0', 'cluster_lambda <2.0')\n",
    "\n",
    "    \n",
    "    plt.subplot(2,3,6)\n",
    "    plt.hist(dataframe['cluster_iso_its_new'], bins=60,  range=(-10,110), color='black',histtype='step', normed=True,\n",
    "             weights=dataframe['weights'], label='ITS')\n",
    "    plt.hist(dataframe['cluster_iso_tpc_04'], bins=60,  range=(-10,110), color='red',histtype='step', normed=True,\n",
    "             weights=dataframe['weights'], label ='TPC')\n",
    "    \n",
    "    plt.hist(dataframe['cluster_iso_cluster_04'], bins=60,  range=(-10,110), color='blue',histtype='step', normed=True,\n",
    "             weights=dataframe['weights'], label ='cluster')\n",
    "    \n",
    "    plt.axvline(x=1.5,color='r',alpha=0.7)\n",
    "    plt.xlabel('ISO (GeV/c)')  \n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('ClusterCutFlow_dataset_%s.pdf'%name)\n",
    "    \n",
    "    \n",
    "    print '# of isolated clusters:'\n",
    "    \n",
    "    isodata = applyCut(dataframe, 'cluster_iso_its_new<1.5', 'cluster_iso_its_new < 1.5 GeV/c:')\n",
    "    applyCut(dataframe, 'cluster_iso_its_new<10 and cluster_iso_its_new>5.0', 'cluster_iso_its_new in 5--10 GeV/c:')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.hexbin(x=isodata['cluster_emax_over_e'], y=isodata['cluster_NN1'], cmap='viridis',bins=\"log\")\n",
    "    plt.xlabel(r'$E_{max}/E_{cluster}$')\n",
    "    plt.ylabel('cluster_NN1')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.hexbin(x=isodata.query('cluster_Lambda<1.5')['cluster_emax_over_e'], y=isodata.query('cluster_Lambda<1.5')['cluster_Lambda'], cmap='viridis',bins=\"log\") \n",
    "    plt.xlabel(r'$E_{max}/E_{cluster}$')\n",
    "    plt.ylabel(r'$\\sigma_{long}^{2}$')\n",
    "    plt.ylim([0.0,1.5])\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('CorrelationDNN_EmaxE_%s.pdf'%name)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))        \n",
    "    #PLOT ISOLATION DISTRIBUTIONS\n",
    "    plt.subplot(4,4,5) \n",
    "    #plt.hist(dataframe['cluster_frixione_its_04_02'], range=(-25,25), bins=100,label='Frixione_its',\n",
    "     #        histtype='step',weights=dataframe['weights'])\n",
    "    #plt.hist(dataframe['cluster_iso_its_04'], range=(-25,25), bins=100,label='Cone_its',\n",
    "      #       histtype='step',weights=dataframe['weights'])\n",
    "    \n",
    "    plt.hist(dataframe['cluster_pt'],bins=50, range=(0.0,50.0),color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    plt.xlabel(r'cluster $p_{T}$ [GeV/c]')\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    \n",
    "\n",
    "    plt.subplot(4,4,6) \n",
    "    plt.hist(dataframe['cluster_iso_its_04_sub'], range=(-50,50), bins=50,label='ITS',\n",
    "             histtype='step',weights=dataframe['weights'])\n",
    "    plt.hist(dataframe['cluster_iso_tpc_04'], range=(-50,50), bins=50,label='TPC',\n",
    "             histtype='step',weights=dataframe['weights'])\n",
    "    plt.hist(dataframe['cluster_iso_cluster_04'], range=(-50,50), bins=50,label='cluster',\n",
    "             histtype='step',weights=dataframe['weights'])\n",
    "\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.legend()\n",
    "    plt.xlabel('cluster isolation (GeV/c)')\n",
    "    \n",
    "    plt.subplot(4,4,7) \n",
    "    plt.hist(dataframe['cluster_ncell'],range=(0,30), bins=30,color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    dataframe = applyCut(dataframe, 'cluster_ncell>2', 'ncell > 2:')\n",
    "    plt.xlabel('Number of cells in cluster')\n",
    "    \n",
    "    plt.subplot(4,4,8)\n",
    "    plt.hist(dataframe['cluster_Lambda'], bins=100,  range=(0,2.0), color='black',histtype='step', normed=True, \n",
    "             label='Lambda',weights=dataframe['weights'])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(4,4,9)\n",
    "    plt.hist(dataframe['cluster_NN1'], bins=50,range=(0,1.0), color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    plt.xlabel('cluster NN')\n",
    "\n",
    " \n",
    "    plt.subplot(4,4,10)\n",
    "    dataframe['cluster_SuperModule'].value_counts().sort_index().plot(kind='bar')\n",
    "    plt.xlabel('cluster supermodule')\n",
    "    \n",
    "    plt.subplot(4,4,11)\n",
    "    dataframe['run_number'].value_counts().sort_index().plot(kind='bar')\n",
    "       \n",
    "    plt.subplot(4,4,12)\n",
    "    plt.hist(dataframe['ncluster'], bins=30, range=(0,30), color='black',histtype='step', \n",
    "             normed=True,weights=dataframe['weights'])\n",
    "    plt.xlabel('# of clusters in event')\n",
    "    \n",
    "    plt.subplot(4,4,13)\n",
    "    plt.hist(dataframe['cluster_emax_over_e'], bins=100,  range=(0,1.0), color='black',histtype='step',\n",
    "             normed=True,weights=dataframe['weights'])\n",
    "    plt.xlabel(r'$E_{max}/E_{cluster}$')\n",
    "\n",
    "    plt.subplot(4,4,14)\n",
    "    #dataframe['npileup_vertex_spd'].value_counts().sort_index().plot(kind='bar')\n",
    "    #plt.xlabel('npileup_vertex_spd')\n",
    "    plt.hist(dataframe['centrality_v0m'], bins = 50, range = (0,100), color ='black', histtype = 'step', normed =True, \n",
    "             weights = dataframe['weights'])\n",
    "    plt.xlabel('centrality')\n",
    "    \n",
    "    plt.subplot(4,4,15)\n",
    "    \n",
    "    \n",
    "    plt.hist(dataframe['cluster_ecross_over_e'],bins=100,color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    dataframe = applyCut(dataframe, 'cluster_ecross_over_e>0.05', 'ecross/e > 0.05 :')\n",
    "    plt.xlabel(r'$E_{cross}/E_{cluster}$')\n",
    "\n",
    "    plt.legend()\n",
    "      \n",
    "    plt.subplot(4,4,16)\n",
    "    plt.hist(dataframe['cluster_nlocal_maxima'], bins=7,  range=(-0.5,6.5), color='black',histtype='step', normed=True,weights=dataframe['weights'])\n",
    "    plt.xlabel('Number of local maxima')  \n",
    "   \n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('Cutflow_dataset_%s.png'%name)\n",
    "\n",
    "    #fig = plt.figure(figsize=(12,12))\n",
    "    #for ism in range(20):\n",
    "    #    plt.subplot(4,5,ism+1)\n",
    "    #    plt.hist(isodata[isodata.cluster_SuperModule==ism]['cluster_NN1'], bins=20,range=(0,1.0), normed=True, color='black',\n",
    "    #             label='SM=%i'%(ism), histtype='step',weights=isodata[isodata.cluster_SuperModule==ism]['weights'])\n",
    "    #    plt.legend(loc='best')\n",
    "    #    plt.ylim([0.0,6.0])\n",
    "\n",
    "            \n",
    "    #fig.savefig('Supermodules_DNN%s.png'%name)\n",
    "    \n",
    "\n",
    "            \n",
    "    #fig.savefig('Supermodules_EmaxOverE%s.png'%name)\n",
    "\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build templates from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIsoSplitHists(data, bins, isoCut, nonisoCuts, var, isovar, varRange):\n",
    "    hfull, binEdges = np.histogram(data[var], bins, range=varRange, weights=data['weights'])\n",
    "    hiso, _ = np.histogram(data.query('%s<%f '%(isovar,isoCut))[var], binEdges, \n",
    "                           range=varRange, weights = data.query('%s<%f '%(isovar,isoCut))['weights'])\n",
    "    hnoniso, _ = np.histogram(data.query('%s>%f and %s<%f'%(isovar,nonisoCuts[0],isovar, nonisoCuts[1]))[var], binEdges, \n",
    "                              range=varRange, weights = data.query('%s>%f and %s<%f'%(isovar,nonisoCuts[0],isovar, nonisoCuts[1]))['weights'])\n",
    "\n",
    "    return hfull, hiso, hnoniso, binEdges\n",
    "\n",
    "#it was 10-15 GeV\n",
    "def getTemplates(dataHists, mcHists, bins, isocut=1.5, nonisocuts=(4,10), var='cluster_NN1', isovar='cluster_iso_its_04_sub', varRange=(0.0, 1.0)):\n",
    "    _, dataiso, datanoniso, binEdges = getIsoSplitHists(dataHists, bins, isocut, nonisocuts, var, isovar, varRange)\n",
    "    #signalmc, _ = np.histogram(mcHists[var], binEdges, range=varRange)\n",
    "    _, signalmc, _bkg, binEdges = getIsoSplitHists(mcHists, bins,isocut,nonisocuts,var,isovar,varRange)\n",
    "     \n",
    "    dataisoerr = np.sqrt(dataiso)\n",
    "    datanonisoerr = np.sqrt(datanoniso)\n",
    "    signalmcerr = np.sqrt(signalmc)\n",
    "    \n",
    "    return dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define template fit and purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haveSameLength(*args):\n",
    "    n = len(args[0])\n",
    "    return all(len(l) == n for l in args)\n",
    "\n",
    "def normalize(x):\n",
    "    return np.array(x, dtype='f')/np.sum(x)\n",
    "\n",
    "def getBinRange(binEdges, valuemin, valuemax):\n",
    "    binmin = min([i for i, edge in enumerate(binEdges) if edge >= valuemin])\n",
    "    binmax = max([i for i, edge in enumerate(binEdges) if edge <= valuemax])\n",
    "    return binmin, binmax\n",
    "    \n",
    "def getPurity(signal, bkg, binEdges, frac, purityMin, purityMax, returnRange=False):\n",
    "    # signal and bkg should be normalized to 1\n",
    "    pmin, pmax = getBinRange(binEdges, purityMin, purityMax)\n",
    "    purity = np.sum(frac*signal[pmin:pmax])/(np.sum([(1-frac)*bkg[pmin:pmax], frac*signal[pmin:pmax]]))\n",
    "    \n",
    "    if returnRange:\n",
    "        return purity, pmin, pmax\n",
    "    else:\n",
    "        return purity\n",
    "    \n",
    "def getEfficiency(signal, binEdges, purityMin, purityMax):\n",
    "    pmin, pmax = getBinRange(binEdges, purityMin, purityMax)\n",
    "    efficiency =  np.sum(signal[pmin:pmax])/np.sum(signal)\n",
    "    \n",
    "    return efficiency\n",
    "\n",
    "class TemplateFit:\n",
    "    def __init__(self, data, dataerr, signal, signalerr, bkg, bkgerr, binEdges, fitRange=None, verbosity=1, fixN=True,\n",
    "                 fixNsig =False, Nsig0=100):       \n",
    "        if not haveSameLength(data, dataerr, signal, signalerr, bkg, bkgerr, binEdges[1:]):\n",
    "            raise ValueError('Inputs do not have the same length (binEdges should have 1 more than the rest)')\n",
    "        \n",
    "        self.data = np.array(data, dtype='f')\n",
    "        self.dataerr = np.array(dataerr, dtype='f')\n",
    "        self.inputSignal = np.array(signal, dtype='f')\n",
    "        self.inputSignalerr = np.array(signalerr, dtype='f')\n",
    "        self.inputBkg = np.array(bkg, dtype='f')\n",
    "        self.inputBkgerr = np.array(bkgerr, dtype='f')\n",
    "        self.binEdges = binEdges\n",
    "        self.fixN = fixN\n",
    "        self.fixNsig = fixNsig\n",
    "        self.Nsig0   = Nsig0\n",
    "        if fitRange:\n",
    "            self.fitRange = getBinRange(binEdges, *fitRange)\n",
    "        else:\n",
    "            self.fitRange = (0, None)\n",
    "        \n",
    "        self.signal = self.inputSignal/np.sum(self.inputSignal)\n",
    "        self.signalerr = self.inputSignalerr/np.sum(self.inputSignal)\n",
    "        self.bkg = self.inputBkg/np.sum(self.inputBkg)\n",
    "        self.bkgerr = self.inputBkgerr/np.sum(self.inputBkg)\n",
    "        self.binCenters = np.array([(hedge+ledge)/2.0 for ledge, hedge in zip(binEdges[:-1], binEdges[1:])])\n",
    "        self.binWidths = np.array([hedge-ledge for ledge, hedge in zip(binEdges[:-1], binEdges[1:])])\n",
    "               \n",
    "        self.signalColor = '#3B7EA1'\n",
    "        self.bkgColor = '#FDB515'\n",
    "        self.figureSize = (10, 8)\n",
    "        \n",
    "        self.verbosity = verbosity\n",
    "               \n",
    "        self.doFit()\n",
    "        \n",
    "    def doFit(self):\n",
    "        def Chi2(N, Nsig):\n",
    "            model = Nsig*self.signal + (N-Nsig)*self.bkg #model = N*(f*self.signal + (1-f)*self.bkg)\n",
    "            totalerror = np.sqrt(np.square(self.dataerr) + np.square((N-Nsig)*self.bkgerr))\n",
    "            return np.sum(np.power(np.divide(self.data-model, totalerror,\n",
    "                                             out=np.zeros_like(totalerror), where=totalerror!=0), 2.0)[slice(*self.fitRange)])\n",
    "\n",
    "        mt = iminuit.Minuit(Chi2, N=np.sum(self.data), fix_N=self.fixN,  Nsig=self.Nsig0, fix_Nsig = self.fixNsig, \n",
    "                            error_N=1, error_Nsig=1, print_level=self.verbosity, limit_Nsig=(0,1e4))#errordef=1,\n",
    "        migradresult = mt.migrad()\n",
    "        \n",
    "        #hesseresult = mt.hesse()\n",
    "        #if(mt.migrad_ok()):\n",
    "        #    mt.hesse()\n",
    "        \n",
    "        if( not mt.migrad_ok()):\n",
    "            mt = iminuit.Minuit(Chi2, N=np.sum(self.data), fix_N=self.fixN,  Nsig=self.Nsig0*1.2, fix_Nsig = self.fixNsig, \n",
    "                            error_N=5, error_Nsig=5, print_level=self.verbosity, limit_Nsig=(0,1e4))#errordef=1\n",
    "            \n",
    "        \n",
    "        if( not mt.migrad_ok()):\n",
    "            mt = iminuit.Minuit(Chi2, N=np.sum(self.data), fix_N=self.fixN,  Nsig=self.Nsig0*1.2, fix_Nsig = self.fixNsig, \n",
    "                            error_N=10, error_Nsig=10, print_level=self.verbosity, limit_Nsig=(0,1e4))#errordef=1\n",
    "    \n",
    "    \n",
    "        if( not mt.migrad_ok()):\n",
    "            mt = iminuit.Minuit(Chi2, N=np.sum(self.data), fix_N=self.fixN,  Nsig=self.Nsig0*1.1, fix_Nsig = self.fixNsig, \n",
    "                            error_N=10, error_Nsig=30, print_level=self.verbosity, limit_Nsig=(0,1e4))#errordef=1\n",
    "        #if(mt.migrad_ok()):\n",
    "        #    mino = mt.minos('Nsig')       \n",
    "        \n",
    "        self.migrad = mt\n",
    "        self.fitN = mt.values['N']\n",
    "        self.fitNerr = 0\n",
    "        self.fitNsig = mt.values['Nsig']\n",
    "        \n",
    "        #if (not self.fixNsig>0 and mt.migrad_ok()):\n",
    "        #    self.fitNsigerr = max(mino['Nsig'].lower, mino['Nsig'].upper)\n",
    "        #else:\n",
    "        self.fitNsigerr = mt.errors['Nsig']\n",
    "        \n",
    "        self.fitSignal = self.fitNsig*self.signal\n",
    "        self.fitSignalerr = self.fitNsig*self.signalerr\n",
    "        self.fitBkg = (self.fitN-self.fitNsig)*self.bkg\n",
    "        self.fitBkgerr = (self.fitN-self.fitNsig)*self.bkgerr\n",
    "        \n",
    "        fitTotal = self.fitSignal + self.fitBkg\n",
    "        \n",
    "        totalerror = np.sqrt( np.square(self.dataerr) + np.square(self.fitBkgerr))\n",
    "      \n",
    "        \n",
    "        self.residuals = np.divide(self.data- fitTotal , totalerror,\n",
    "                                   out=np.zeros_like(totalerror), where=totalerror!=0)\n",
    "        self.chi2 = Chi2(self.fitN, self.fitNsig)\n",
    "        self.dof = len(self.data[slice(*self.fitRange)])-3\n",
    "\n",
    "    def getPurity(self, purityMin, purityMax):\n",
    "        purity, pmin, pmax = getPurity(self.signal, self.bkg, self.binEdges, self.fitNsig/self.fitN, purityMin, purityMax, True)\n",
    "        puritylow = getPurity(self.signal, self.bkg, self.binEdges, (self.fitNsig-self.fitNsigerr)/self.fitN, purityMin, purityMax)\n",
    "        purityhigh = getPurity(self.signal, self.bkg, self.binEdges,  (self.fitNsig+self.fitNsigerr)/self.fitN, purityMin, purityMax)\n",
    "        #if self.verbosity == 1:\n",
    "        #    print 'Purity = %2.5f, +%2.5f, -%2.5f'%(purity, purityhigh-purity, purity-puritylow)\n",
    "        return purity,  pmin, pmax\n",
    "    \n",
    "    def getEfficiency(self, purityMin,purityMax):\n",
    "        efficiency = getEfficiency(self.signal,self.binEdges,purityMin,purityMax)\n",
    "        return efficiency\n",
    "        \n",
    "    def plotFit(self, xlabel, title,  showPurity=False, purityMin=0.0, purityMax=1.0, newFigure=True, ylimit=-1.0,\n",
    "                figureFilename='', normalize=True):\n",
    "        if newFigure:\n",
    "            fig = plt.figure(figsize=self.figureSize)\n",
    "        \n",
    "        if normalize:\n",
    "            norm = self.fitN*(self.binCenters[1]-self.binCenters[0])\n",
    "        else:\n",
    "            norm = 1\n",
    "            \n",
    "            \n",
    "        fig.add_axes((0.1,0.3,0.88,0.6))\n",
    "        dataplot = plt.errorbar(self.binCenters, self.data/norm,yerr= self.dataerr/norm, label='Data, Iso',fmt='ko',alpha=.65)\n",
    "       \n",
    "        bkgplot = plt.bar(self.binCenters, self.fitBkg/norm, width=self.binWidths, #yerr=self.fitBkgerr/norm, \n",
    "                align='center', label='Bkg (data non-Iso)', capsize=0,\n",
    "                color=self.bkgColor)#, ec=self.bkgColor, ecolor='gray') remove from now\n",
    "        \n",
    "        \n",
    "        toterror = np.sqrt(np.power(self.fitBkgerr,2.0))#+np.power(self.fitSignalerr,2.0))###FIX ME\n",
    "        signalplot = plt.bar(self.binCenters, (self.fitSignal)/norm, yerr= toterror/norm, bottom=self.fitBkg/norm, width=self.binWidths,\n",
    "                align='center', label='Signal (MC)', capsize=4,\n",
    "                color=self.signalColor, ec=self.signalColor, ecolor='gray') \n",
    "\n",
    "        \n",
    "        staterrplot =plt.errorbar([0.5,0.5], [0,0],  yerr=[0,0], capsize=4, color='gray', label='Stat. error template',fmt=' ')\n",
    "        \n",
    "        purity, pmin, pmax = self.getPurity(purityMin, purityMax)\n",
    "        chi2_insignalregion = sum(np.square(self.residuals)[pmin:pmax])/len(np.square(self.residuals)[pmin:pmax]-2)\n",
    "        chi2text, = plt.plot([], [], ' ', label=r'$\\chi^{2}$/dof=%2.1f'%(self.chi2/self.dof))    \n",
    "        total = np.sum(self.data)\n",
    "        #fitresultslabel ='$N_{sig}$=%2.0f$\\pm$%2.0f'%(self.fitNsig,self.fitNsigerr)         \n",
    "        ptrangetext, = plt.plot( [], [], ' ', label=title)\n",
    "        #templateerrortext, = plt.plot([], [], ' ', label ='Stat. error template', color='gray')\n",
    "                    \n",
    "        #If bkg only fit, then show the range used in fit\n",
    "        if self.fixNsig:\n",
    "            ax = plt.gca()\n",
    "\n",
    "            \n",
    "            ax.axvspan(self.binCenters[self.fitRange[0]]-self.binWidths[self.fitRange[0]]/2.0, \n",
    "                       self.binCenters[self.fitRange[1]]-self.binWidths[self.fitRange[1]]/2.0,color='red', alpha=0.4,\n",
    "                       label='fit region')\n",
    "            \n",
    "            purity, pmin, pmax = self.getPurity(puritymin, puritymax)\n",
    "            total = np.sum(self.data[pmin:pmax])\n",
    "            bkg_estimate = self.fitN*np.sum(self.bkg[pmin:pmax]) \n",
    "            signal_estimate = (total-(1-self.fitNsig)*bkg_estimate)\n",
    "            purity = signal_estimate/total\n",
    "            plt.title('%s; Purity=%2.0f%%'%(title, 100.0*purity))\n",
    "            ax.axvspan(self.binCenters[pmin]-self.binWidths[pmin]/2.0,self.binCenters[pmax]+self.binWidths[pmax]/2.0,\n",
    "                       color='black', alpha=0.2)\n",
    "\n",
    "\n",
    "        elif showPurity:\n",
    "            purity, pmin, pmax = self.getPurity(purityMin, purityMax)\n",
    "            puritylow = getPurity(self.signal, self.bkg, self.binEdges, (self.fitNsig-self.fitNsigerr)/self.fitN, purityMin, purityMax)\n",
    "            purityhigh = getPurity(self.signal, self.bkg, self.binEdges,  (self.fitNsig+self.fitNsigerr)/self.fitN, purityMin, purityMax)\n",
    "            \n",
    "            nsignal = purity*sum(self.data[pmin:pmax])\n",
    "            nsignal_all = purity*sum(self.data)\n",
    "            \n",
    "            total = np.sum(self.data)\n",
    "\n",
    "            bkg_estimate = self.fitN*np.sum(self.bkg) \n",
    "\n",
    "            signal_estimate = (self.data*self.fitN)\n",
    "            \n",
    "\n",
    "            ax = plt.gca()\n",
    "            #ax.axvspan(self.binCenters[pmin]-self.binWidths[pmin]/2.0,self.binCenters[pmax]-self.binWidths[pmax]/2.0,\n",
    "            #          color='black', alpha=0.1)\n",
    "            \n",
    "            #plt.title('%s; Purity=%2.0f$\\pm$%2.0f%%'%(title, 100.0*purity, 100.0*(purityhigh-purity)))\n",
    "            #plt.title('%s; Purity=%2.0f%%'%(title, 100.0*purity))\n",
    "            #plt.title(title,fontsize=18)\n",
    "        else:\n",
    "            print 'nada'#plt.suptitle(title)\n",
    "\n",
    "\n",
    "        #plt.annotate('ALICE Internal, %s'%(dataname), xy=(0.05, 0.95), fontsize=16, xycoords='axes fraction')\n",
    "        legend = plt.legend(handles=[dataplot, signalplot, bkgplot, staterrplot , chi2text,ptrangetext], ncol=1, numpoints=1, \n",
    "                            loc='best', fontsize=17,frameon=False,title='ALICE Performance\\n%s'%(dataname))\n",
    "        if self.fixNsig:\n",
    "            legend = plt.legend(handles=[dataplot, bkgplot, chi2text], ncol=1, numpoints=1, loc='best', \n",
    "                                fontsize=18,frameon=False,title='ALICE Performance\\n%s'%(dataname))\n",
    "        plt.setp(legend.get_title(),fontsize=18)\n",
    "   \n",
    "        plt.xlabel(xlabel,fontsize=22)\n",
    "        plt.ylabel('Entries',fontsize=20)\n",
    "        if ylimit>0:\n",
    "            plt.ylim([0.0,ylimit])\n",
    "        \n",
    "      \n",
    "\n",
    "        if True:\n",
    "            fig.add_axes((0.1,0.1,0.88,0.2)) \n",
    "            plt.plot(self.binCenters, self.residuals, 'o',color='black',alpha=0.65)\n",
    "            plt.xlabel(xlabel, fontsize=22)\n",
    "            plt.ylabel('(Data-Fit)/Error',fontsize=16)\n",
    "            #plt.ylim([-7.9,7.9])\n",
    "            \n",
    "            plt.ylim([-8.9,8.9])\n",
    "            \n",
    "            average = np.average(self.residuals)\n",
    "            std    = np.std(self.residuals)\n",
    "            if not self.fixNsig:\n",
    "                plt.axhline(y=average,color='r',label='Average')\n",
    "            else: \n",
    "                plt.axhline(y=0,color='blue',label='0.0')\n",
    "            #plt.axhline(y=average+std,color='r',linestyle='--', label='+/- RMS')\n",
    "            plt.legend(loc='best',frameon=False,fontsize=18)\n",
    "\n",
    "        if newFigure:\n",
    "            plt.show()\n",
    "            \n",
    "        if figureFilename:\n",
    "            #fig.tight_layout()\n",
    "            fig.savefig(figureFilename)\n",
    "            \n",
    "    def plotResiduals(self, xlabel, figureFilename=''):\n",
    "        fig = plt.figure(figsize=(10,4))\n",
    "        plt.plot(self.binCenters, self.residuals, 'o')\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel('(Data-Fit)/Erorr')\n",
    "        plt.ylim([-6.5,6.5])\n",
    "        average = np.average(self.residuals)\n",
    "        std    = np.std(self.residuals)\n",
    "        plt.axhline(y=average,color='r',label='Average')\n",
    "        #plt.axhline(y=average+std,color='r',linestyle='--', label='+/- RMS')\n",
    "        plt.legend(loc='best')\n",
    "        #plt.axhline(y=average-std,color='r',linestyle='--')\n",
    "\n",
    "        if figureFilename:\n",
    "            fig.savefig(figureFilename)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plotProfile(self, xlabel, figureFilename=''):\n",
    "        fig = plt.figure(figsize=self.figureSize)\n",
    "        self.migrad.draw_mnprofile('f', bound=3,subtract_min=True,text=False);\n",
    "        plt.show()\n",
    "        if figureFilename:\n",
    "            fig.savefig(figureFilename)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def plotTemplates(self, xlabel, figureFilename=''):\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        plt.bar(self.binCenters, self.fitSignal/np.sum(self.fitSignal), width=self.binWidths, align='center', label='Signal (MC)',\n",
    "                color=self.signalColor, ec=self.signalColor, alpha=0.8, capsize=0, linewidth=0)\n",
    "        plt.bar(self.binCenters, self.fitBkg/np.sum(self.fitBkg), width=self.binWidths, align='center', label='Background\\n(sideband data)',\n",
    "                color=self.bkgColor, ec=self.bkgColor, alpha=0.5, capsize=0, linewidth=0)\n",
    "        plt.xlabel(xlabel,fontsize=18)\n",
    "        plt.ylabel('Probability',fontsize=17)\n",
    "        plt.legend(loc='best',fontsize=15)\n",
    "        \n",
    "        if figureFilename:\n",
    "            fig.savefig(figureFilename)\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def plotNormalizedTemplates(self, xlabel, figureFilename=''):\n",
    "        fig = plt.figure(figsize=(self.figureSize[0], self.figureSize[1]/2.0))\n",
    "        plt.bar(self.binCenters, self.signal, width=self.binWidths, align='center', label='Signal (MC)',\n",
    "                color=self.signalColor, ec=self.signalColor, alpha=0.4)\n",
    "        plt.bar(self.binCenters, self.bkg, width=self.binWidths, align='center', label='Background (data)',\n",
    "                color=self.bkgColor, ec=self.bkgColor, alpha=0.4)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel('Entries')\n",
    "        plt.legend(loc='best')\n",
    "        \n",
    "        if figureFilename:\n",
    "            fig.savefig(figureFilename)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to perform fits over many datasets and/or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFitResults(datasets, signals, bkgs, binEdges, mixSets=True, pmin=None, pmax=None, fitRange=None, verbosity=0, showDistributions=False):\n",
    "    fitfvals = array('f')\n",
    "    fitNvals = array('f')\n",
    "    purvals = array('f')\n",
    "    fitresiduals = []\n",
    "    \n",
    "    if pmin == None:\n",
    "        pmin = binEdges[0]\n",
    "    if pmax == None:\n",
    "        pmax = binEdges[-1]\n",
    "    \n",
    "    if mixSets:\n",
    "        makeCombos = itertools.product\n",
    "    else:\n",
    "        makeCombos = zip\n",
    "        \n",
    "    for (dataset, signal, bkg) in makeCombos(datasets, signals, bkgs):\n",
    "        tf = TemplateFit(dataset, np.sqrt(dataset), signal, np.sqrt(signal),\n",
    "                         bkg, np.sqrt(bkg), binEdges, fitRange=fitRange, verbosity=verbosity)\n",
    "        fitfvals.append(tf.fitNsig)\n",
    "        fitNvals.append(tf.fitN)\n",
    "        purvals.append(tf.getPurity(pmin, pmax)[0])\n",
    "        fitresiduals.append(tf.residuals)\n",
    "        \n",
    "    if showDistributions:\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.subplot(131)\n",
    "        amlplot.hist(fitfvals, 'knuth')\n",
    "        plt.xlabel('Signal fraction')\n",
    "        plt.subplot(132)\n",
    "        amlplot.hist(fitNvals, 'knuth')\n",
    "        plt.xlabel('Normalization')\n",
    "        plt.subplot(133)\n",
    "        amlplot.hist(purvals, 'knuth')\n",
    "        plt.xlabel('Purity')\n",
    "        \n",
    "        plt.figure(figsize=(12,6))        \n",
    "        binCenters = np.array([(hedge+ledge)/2.0 for ledge, hedge in zip(binEdges[:-1], binEdges[1:])])\n",
    "        binWidths = np.array([hedge-ledge for ledge, hedge in zip(binEdges[:-1], binEdges[1:])])\n",
    "        plt.plot(binCenters, np.mean(fitresiduals, axis=0), 'ko')\n",
    "        plt.ylabel('Average (Fit-data)/dataerr')\n",
    "        \n",
    "        plt.show()\n",
    "        print 'Number of results: %i'%len(fitfvals)\n",
    "    \n",
    "    return fitfvals, fitNvals, purvals\n",
    "\n",
    "def varyWithinBins(realShape, nVariations):\n",
    "    realShape = np.array(realShape)\n",
    "    return np.random.poisson(lam=realShape, size=(nVariations, realShape.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculate fit uncertainty due to statistical uncertainty on template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFitUncertainty(data, signal, bkg, binEdges, pmin=None, pmax=None, fitRange=None):\n",
    "    signals = varyWithinBins(signal, 100)\n",
    "    bkgs = varyWithinBins(bkg, 100)\n",
    "    fitfvals, fitNvals, purvals = getFitResults([data], signals, bkgs, binEdges,\n",
    "                                                pmin=pmin, pmax=pmax, fitRange=fitRange, verbosity=0, showDistributions=True)\n",
    "    print 'Signal fraction: %2.3f, sigma: %2.3f'%(np.mean(fitfvals), np.std(fitfvals))\n",
    "    print 'Normalization: %2.2f, sigma: %2.2f'%(np.mean(fitNvals), np.std(fitNvals))\n",
    "    print 'Purity: %2.5f, sigma: %2.5f'%(np.mean(purvals), np.std(purvals))\n",
    "\n",
    "def plotFitUncertaintyExamples(data, dataerr, inputSignal, inputBkg, binEdges):\n",
    "    signals = varyWithinBins(inputSignal, 2)\n",
    "    bkgs = varyWithinBins(inputBkg, 2)\n",
    "    plt.figure(figsize=(15,12))\n",
    "    for i, (signal, bkg) in enumerate(itertools.product(signals, bkgs)):\n",
    "        plt.subplot(2,2,i+1)\n",
    "        tf = TemplateFit(data, dataerr, signal, np.sqrt(signal), bkg, np.sqrt(bkg), binEdges, verbosity=0)\n",
    "        tf.plotFit('', '', newFigure=False)\n",
    "        ax = plt.gca()\n",
    "        ax.legend_.remove()\n",
    "        ax.set_ylabel('')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check closure of template fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkClosure(signal, bkg, binEdges, norm, f, nDatasets, verbosity=0, showDistributions=False):\n",
    "    normSignal = signal/np.sum(signal)\n",
    "    normBkg = bkg/np.sum(bkg)\n",
    "    realShape = norm*(f*normSignal + (1-f)*normBkg)\n",
    "    datasets = varyWithinBins(realShape, nDatasets)\n",
    "    \n",
    "    fitfvals, fitNvals, purvals = getFitResults(datasets, [signal], [bkg], binEdges, verbosity=verbosity, showDistributions=showDistributions)\n",
    "    return {'fmean': np.mean(fitfvals), 'fsigma': np.std(fitfvals), 'ftrue': f,\n",
    "            'Nmean': np.mean(fitNvals), 'Nsigma': np.std(fitNvals)}\n",
    "\n",
    "def checkClosureOverParameters(data, signal, bkg, binEdges, nDatasets):\n",
    "    datanorm = int(np.sum(data))\n",
    "    normvals = [datanorm, datanorm/2, datanorm/4, datanorm*2]\n",
    "    fvals = np.linspace(0.0, 1.0, num=11)\n",
    "\n",
    "    results = {}\n",
    "    for (norm, f) in itertools.product(normvals, fvals):\n",
    "        results[(norm, f)] = checkClosure(signal, bkg, binEdges, norm, f, nDatasets)\n",
    "    \n",
    "    return results, fvals, normvals\n",
    "\n",
    "def plotCheckClosureResults(results, fvals, normvals):\n",
    "    plots = {norm: [] for norm in normvals}\n",
    "    for (norm, f), result in results.iteritems():\n",
    "        plots[norm].append((result['fmean'], result['fsigma'], result['ftrue'], result['Nmean']/norm, result['Nsigma']/norm))\n",
    "\n",
    "    plt.figure(1, figsize=(12,12))\n",
    "    plt.figure(2, figsize=(12,12))\n",
    "    \n",
    "    sortedNorms = sorted(plots.keys())\n",
    "    for i, norm in enumerate(sortedNorms, 1):\n",
    "        fmean, fsigma, ftrue, ratiomean, ratiosigma = zip(*plots[norm])\n",
    "        plt.figure(1)\n",
    "        plt.subplot(2,2,i)\n",
    "        plt.errorbar(ftrue, fmean, fsigma, fmt='ko')\n",
    "        plt.plot([0,1], [0,1], 'y:')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim([-0.1, 1.1])\n",
    "        ax.set_ylim([-0.1, 1.1])\n",
    "        ax.text(0.0, 1.0, '%i events'%norm, fontsize=20)\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.subplot(2,2,i)\n",
    "        plt.errorbar(ftrue, ratiomean, ratiosigma, fmt='ko')\n",
    "        plt.plot([0,1], [1,1], 'y:')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim([-0.1, 1.1])\n",
    "        ax.set_title('%i events'%norm, fontsize=20)\n",
    "        \n",
    "    plt.suptitle('Fit norm/actual norm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife resampling\n",
    "https://en.wikipedia.org/wiki/Jackknife_resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeJackknifeDatasets(dataset, nDatasets):\n",
    "    nEvents = dataset.shape[0]\n",
    "    dropIndices = range(0, nEvents, nEvents/nDatasets)\n",
    "    return [dataset.drop(dataset.index[slice(*indices)]) for indices in zip(dropIndices[:-1], dropIndices[1:])]\n",
    "\n",
    "def jackknifeResampling(fullData, nDatasets, signal, binEdges, pmin, pmax, fitRange=None):\n",
    "    jkDatasets = makeJackknifeDatasets(fullData, nDatasets)\n",
    "    \n",
    "    dataisos = []\n",
    "    signalmcs = []\n",
    "    datanonisos = []\n",
    "    \n",
    "    for dataset in jkDatasets:\n",
    "        h, dataiso, datanoniso, b = getIsoSplitHists(dataset, binEdges,\n",
    "                                                     isoCut=4, nonisoCuts=(5,15),\n",
    "                                                     var='cluster_NN1', varRange=(0.0, 1.0))\n",
    "        dataisos.append(dataiso)\n",
    "        signalmcs.append(signal)\n",
    "        datanonisos.append(datanoniso)\n",
    "    \n",
    "    fitfvals, fitNvals, purvals = getFitResults(datasets, signals, bkgs, binEdges,\n",
    "                                                mixSets=False, pmin=pmin, pmax=pmax, fitRange=fitRange)\n",
    "    \n",
    "    print 'Signal fraction: %2.3f, sigma: %2.3f'%(np.mean(fitfvals), np.std(fitfvals))\n",
    "    print 'Normalization: %2.2f, sigma: %2.2f'%(np.mean(fitNvals), np.std(fitNvals))\n",
    "    print 'Purity: %2.5f, sigma: %2.5f'%(np.mean(purvals), np.std(purvals))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process NTuples\n",
    "```NTuples found in /project/projectdirs/alice/NTuples on pdsf```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pattern 'cluster_iso_cluster_04' didn't match any branch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-616a3435bf6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmcSignal_Hists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mapplyCuts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0misMC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmcSignal_Files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#mcSignal_Hists = applyCuts( getData(mcSignal_Files),mcSignal_Files[0],isMC=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d10ad952527e>\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(inputFiles)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputFilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputFiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_flatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/root_pandas/readwrite.pyc\u001b[0m in \u001b[0;36mread_root\u001b[0;34m(paths, key, columns, ignore, chunksize, where, flatten, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_noexpand_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_braces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mall_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matching_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoexpand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/root_pandas/readwrite.pyc\u001b[0m in \u001b[0;36mget_matching_variables\u001b[0;34m(branches, patterns, fail)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I think this is impossible?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pattern '{}' didn't match any branch\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pattern 'cluster_iso_cluster_04' didn't match any branch"
     ]
    }
   ],
   "source": [
    "mcSignal_Files = ['17g6a1_pt2.root', '17g6a1_pt3.root', '17g6a1_pt4.root',       '17g6a1_pt5.root']\n",
    "#mcSignal_Files = ['Skimmed_18b10a_pthat1to6.root']\n",
    "\n",
    "\n",
    "\n",
    "mcSignal_Hists = pd.concat([ applyCuts(getData([name]), name ,isMC=True)  for name in mcSignal_Files])\n",
    "\n",
    "#mcSignal_Hists = applyCuts( getData(mcSignal_Files),mcSignal_Files[0],isMC=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataname = r'p-Pb $\\sqrt{s_{\\mathrm{NN}}}$ = 5 TeV'\n",
    "dataFiles = ['Skimmed_13def.root']\n",
    "#dataname = 'pp $\\sqrt{s} =$ 5 TeV'\n",
    "#dataFiles = ['Skimmed_17q.root']\n",
    "\n",
    "\n",
    "#dataHists = applyCuts( getData(dataFiles),dataFiles[0],isMC=False)\n",
    "dataHists = pd.concat([ applyCuts(getData([name]), name ,isMC=False)  for name in dataFiles])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcBKG_Files = ['18g7a_pt1.root','18g7a_pt2.root', '18g7a_pt3.root','18g7a_pt4.root', \n",
    "              '18g7a_pt5.root','18g7a_pt6.root', '18g7a_pt7.root','18g7a_pt8.root',\n",
    "              '18g7a_pt9.root','18g7a_pt10.root', '18g7a_pt11.root','18g7a_pt12.root']\n",
    "\n",
    "mcBKG_Hists = pd.concat([ applyCuts(getData([name]), name ,isMC=True)  for name in mcBKG_Files])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSEUDO DATA for closure studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fakeData = pd.concat([mcBKG_Hists.query('cluster_iso_its_new<1.5')[:60000], \n",
    "                      mcBKG_Hists.query('cluster_iso_its_new>1.5'),\n",
    "                      mcSignal_Hists.query('cluster_iso_its_new<1.5')[:0]]) \n",
    "print fakeData.shape[0]\n",
    "plt.show()\n",
    "\n",
    "dataHists = fakeData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dic = {}\n",
    "fitRange_dic = {}\n",
    "xlabel_dic = {}\n",
    "varname_dic = {}\n",
    "puritymin_dic = {}\n",
    "puritymax_dic = {}\n",
    "limit_yaxis_dic = {}\n",
    "fitRangeBKGonly_dic = {}\n",
    "Range_dic = {}\n",
    "bias =      {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dic['NN'] = 100 #240 #9v.30)\n",
    "fitRange_dic['NN'] = (0.00, 0.90) #0.05 --0.90\n",
    "xlabel_dic['NN'] = 'Deep Neural Network Output'\n",
    "varname_dic['NN'] = 'cluster_NN1'\n",
    "puritymin_dic['NN'] = 0.70\n",
    "puritymax_dic['NN'] = 0.90\n",
    "limit_yaxis_dic['NN'] = 6.1\n",
    "fitRangeBKGonly_dic['NN']=(0.0, 0.3)#(0.08, 0.23)\n",
    "Range_dic['NN']=(0.0,1.0)\n",
    "bias['NN'] = 0.10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emax over Ecluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dic['Emax'] = 80 #200#\n",
    "fitRange_dic['Emax']  = (0.04, 1.0) #0.05 --0.90\n",
    "xlabel_dic['Emax']  = r'$E_{\\mathrm{max}}/E_{\\mathrm{cluster}}$'\n",
    "varname_dic['Emax']  = 'cluster_emax_over_e'\n",
    "puritymin_dic['Emax']  = 0.75#0.75\n",
    "puritymax_dic['Emax']  = 0.95#\n",
    "limit_yaxis_dic['Emax']  = 6.1\n",
    "fitRangeBKGonly_dic['Emax'] =(0.0, 0.55)\n",
    "Range_dic['Emax'] =(0.0,1.0)\n",
    "bias['Emax'] = 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dic['Lambda'] = 220\n",
    "fitRange_dic['Lambda'] = (0.0, 1.2)\n",
    "xlabel_dic['Lambda'] = r'$\\sigma_{\\mathrm{long}}^{2}$'\n",
    "varname_dic['Lambda'] = 'cluster_Lambda'\n",
    "limit_yaxis_dic['Lambda'] = 13.0\n",
    "puritymin_dic['Lambda'] = 0.0\n",
    "puritymax_dic['Lambda'] = 0.3\n",
    "fitRangeBKGonly_dic['Lambda']=(0.4, 1.1)#1.5\n",
    "Range_dic['Lambda']=(0.0,1.2)\n",
    "bias['Lambda'] = 0.07\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##ANGLE LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dic['LambdaAngle']  = 200\n",
    "fitRange_dic['LambdaAngle']= (0.1, 1.2) #(0.0, 1.5)\n",
    "xlabel_dic['LambdaAngle'] = r'$\\sigma_{\\mathrm{long}}^{2}$ Angle'\n",
    "varname_dic['LambdaAngle'] = 'cluster_Lambda_Angle'\n",
    "limit_yaxis_dic['LambdaAngle'] = 13.0\n",
    "\n",
    "puritymin_dic['LambdaAngle'] = 0.0\n",
    "puritymax_dic['LambdaAngle'] = 0.3\n",
    "fitRangeBKGonly_dic['LambdaAngle']=(0.4, .80)#1.5\n",
    "Range_dic['LambdaAngle']=(0.0,1.2)\n",
    "bias['LambdaAngle'] = 0.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run template fit over different pt ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomax=1.5\n",
    "nonisorange=(5.0,10)\n",
    "isolation = 'cluster_iso_its_new'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.logspace(np.log10(12.0), np.log10(13.0), num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsig = {}\n",
    "NsigError = {}\n",
    "#binedges = [ 12.453 ,   13.5, 14.0,  16.0, 17.5,  20.0, 25.0, 30.0  ,50 ] #for pPb--reduced\n",
    "\n",
    "purity = {}\n",
    "purityError = {}\n",
    "puritySysUp = {}\n",
    "puritySysDo = {}\n",
    "purity_bkgonlymethod = {}\n",
    "chi2perdof = {}\n",
    "\n",
    "efficiency = {}\n",
    "\n",
    "\n",
    "\n",
    "#binedges = [ 12.453 ,   13.5, 14.0,  16.0, 18.0,  20.0, 25.0, 30.0  ,40 ] #for pPb--reduced v3.0\n",
    "binedges = [20.0,25.0]\n",
    "\n",
    "\n",
    "bincenters = np.array([(hedge+ledge)/2.0 for ledge, hedge in zip(binedges[:-1], binedges[1:])])\n",
    "binwidth = np.array([abs(hedge-ledge)/2.0 for ledge, hedge in zip(binedges[:-1], binedges[1:])])\n",
    "\n",
    "\n",
    "\n",
    "for varkey in ['Emax','NN','Lambda','LambdaAngle']:# ['NN','Lambda','Emax']:\n",
    "\n",
    "    bins = bins_dic[varkey]  \n",
    "    fitRange = fitRange_dic[varkey]\n",
    "    xlabel = xlabel_dic[varkey] \n",
    "    varname = varname_dic[varkey] \n",
    "    limit_yaxis = limit_yaxis_dic[varkey] \n",
    "\n",
    "    puritymin = puritymin_dic[varkey] \n",
    "    puritymax =  puritymax_dic[varkey] \n",
    "    fitRangeBKGonly=fitRangeBKGonly_dic[varkey] \n",
    "    Range=Range_dic[varkey] \n",
    "\n",
    "    tag = dataFiles[0].split('_small')[0]+mcSignal_Files[0].split('_small')[0]+isolation\n",
    "\n",
    "\n",
    "    purity[varkey]                 = []\n",
    "    purityError[varkey]            = []\n",
    "    puritySysDo[varkey]            = []\n",
    "    puritySysUp[varkey]            = []\n",
    "    purity_bkgonlymethod[varkey]   = [] \n",
    "    chi2perdof[varkey]                     = []\n",
    "    \n",
    "    Nsig[varkey] = []\n",
    "    NsigError[varkey] = []\n",
    "    efficiency[varkey] =[]\n",
    "    \n",
    "    previousResult = 1000\n",
    "    for ipt in range(len(binedges)-1):\n",
    "        ptmin = binedges[ipt]\n",
    "        ptmax = binedges[ipt+1]\n",
    "        #print title\n",
    "        title = r'%2.0f<$p_{\\mathrm{T}}$<%2.0f GeV/$c$'%(ptmin, ptmax)\n",
    "        print title\n",
    "\n",
    "        maskpt_do = dataHists.cluster_pt>ptmin\n",
    "        maskpt_up = dataHists.cluster_pt<ptmax\n",
    "        maskdata = maskpt_do & maskpt_up \n",
    "\n",
    "        mcmaskpt_do = mcSignal_Hists.cluster_pt>ptmin\n",
    "        mcmaskpt_up = mcSignal_Hists.cluster_pt<ptmax  \n",
    "        maskmc   = mcmaskpt_do & mcmaskpt_up\n",
    "    \n",
    "        Templates = getTemplates(dataHists[maskdata], mcSignal_Hists[maskmc], bins,  isocut=isomax, nonisocuts=nonisorange, \n",
    "                                 var = varname,  varRange=Range, isovar=isolation)\n",
    "        dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, fitRange=fitRange)\n",
    "       \n",
    "    \n",
    "        ##BACKGROUND ONLY FIT\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, \n",
    "                         fitRange=fitRangeBKGonly, fixN=False,fixNsig=True,Nsig0=0.0,verbosity=0)\n",
    "        #tf.plotFit(xlabel, title, False, puritymin, puritymax, normalize=False,figureFilename=varname+'ptmin%2.0f_ptmax%2.0f_%s_Iso_%2.0f_Noniso%2.0f_%2.0f_BKGONLYFIT.pdf'%(ptmin,ptmax,tag,10.0*isomax, 10.0*nonisorange[0],10.0*nonisorange[1]))\n",
    "\n",
    "        p, pmin, pmax = tf.getPurity(puritymin, puritymax)\n",
    "        \n",
    "        total = np.sum(tf.data[pmin:pmax])\n",
    "        bkg_estimate = tf.fitN*np.sum(tf.bkg[pmin:pmax]) \n",
    "        signal_estimate = (total-(1-tf.fitNsig)*bkg_estimate)\n",
    "        p = signal_estimate/total\n",
    "             \n",
    "        purity_bkgonlymethod[varkey].append(p)\n",
    "        print 'bkg only purity' , p\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        #perform normal fit, with simulation. Use bkg-only fit Nsig as starting value.\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, Nsig0= signal_estimate , fitRange=fitRange)\n",
    "\n",
    "        tf.plotFit(xlabel, title, True, puritymin, puritymax,\n",
    "                   normalize=False, \n",
    "                   figureFilename=varname+'ptmin%2.0f_ptmax%2.0f_%s_Iso%2.0f_Noniso%2.0f_%2.0f.pdf'%(ptmin,ptmax,tag,isomax, nonisorange[0],nonisorange[1]))\n",
    "   \n",
    "        Nsig[varkey].append(tf.fitNsig)\n",
    "        previousResult = tf.fitNsig\n",
    "        NsigError[varkey].append(tf.fitNsigerr)\n",
    "   \n",
    "        #get chi2/dof\n",
    "        chi2perdof[varkey].append(tf.chi2/tf.dof)\n",
    "\n",
    "        ##get purity\n",
    "        p, pmin, pmax = tf.getPurity(puritymin, puritymax)\n",
    "        eff = tf.getEfficiency(puritymin,puritymax)\n",
    "        efficiency[varkey].append(eff)\n",
    "        puritylow = getPurity(tf.signal, tf.bkg, tf.binEdges, (tf.fitNsig-tf.fitNsigerr)/tf.fitN, puritymin, puritymax)\n",
    "        purityhigh = getPurity(tf.signal, tf.bkg, tf.binEdges,  (tf.fitNsig+tf.fitNsigerr)/tf.fitN, puritymin, puritymax)\n",
    "        print varkey\n",
    "        print 'ptmin = %2.2f; ptmax =%2.2f // purity %2.2f =/- %2.2f'%(ptmin, ptmax, p,  max(abs(p-puritylow), abs(p-purityhigh) ))\n",
    "        print 'efficiency=%2.2f' %(eff)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        purity[varkey].append(p-bias[varkey])\n",
    "        perror = max(abs(p-puritylow), abs(p-purityhigh))\n",
    "        if perror < 0.01:\n",
    "            perror = round(perror,2)\n",
    "        purityError[varkey].append( perror)\n",
    "        #puritySysDo[varkey].append((p-bias[varkey])  -np.sqrt(0.06*0.06+perror*perror))\n",
    "        #puritySysUp[varkey].append( (p-bias[varkey]) +np.sqrt(0.06*0.06+perror*perror))\n",
    "        puritySysDo[varkey].append((p-bias[varkey])- 0.06)\n",
    "        puritySysUp[varkey].append( (p-bias[varkey]) + 0.06)\n",
    "        \n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "myfontsize = 23\n",
    "xmaximo = 40\n",
    "label = {}\n",
    "label['Lambda'] = r'$\\sigma_{\\mathrm{long}}^{2}$'\n",
    "label['LambdaAngle'] = r'$\\sigma_{\\mathrm{long}}^{2}$ Angle'\n",
    "\n",
    "label['Emax']   =  r'$E_{\\mathrm{max}}/E_{\\mathrm{cluster}}$'\n",
    "label['NN']     = 'DNN'\n",
    "\n",
    "color = {}\n",
    "color['Lambda'] = 'dodgerblue'\n",
    "color['Emax']   = 'green'\n",
    "color['NN']     = 'orange'\n",
    "\n",
    "for varkey in ['NN','Emax','Lambda']:\n",
    "    plt.errorbar(bincenters,Nsig[varkey]/(2*binwidth), xerr = binwidth, yerr = NsigError[varkey]/(2*binwidth), \n",
    "                 label=label[varkey], linestyle=\"None\",marker='o', alpha=0.85)\n",
    "\n",
    "    \n",
    "a = Nsig['Lambda']\n",
    "b = Nsig['NN']\n",
    "c = Nsig['Emax']\n",
    "l = [a,b,c]\n",
    "average = [sum(i)/3.0 for i in zip(*l)]\n",
    "\n",
    "\n",
    "plt.errorbar(bincenters,average/(2*binwidth), label='Average', linestyle=\"-\", linewidth=2.5, alpha=0.85, marker=None,color='black')\n",
    "\n",
    "plt.legend(loc='best',fontsize=myfontsize,frameon=False)\n",
    "plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.ylabel(r'dN/d$p_{\\mathrm{T}}$',fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ [GeV/c]',fontsize=myfontsize)\n",
    "#plt.ylim(ymin=0.0)\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('Spectra_%s.pdf'%dataFiles[0])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "\n",
    "for varkey in ['NN','Emax','Lambda']:\n",
    "    \n",
    "    plt.errorbar(bincenters,np.divide(Nsig[varkey],average), xerr = binwidth,  yerr=np.divide(NsigError[varkey],average),\n",
    "                 label=label[varkey], linestyle=\"None\", marker='o', alpha=0.5)\n",
    "\n",
    "    \n",
    "plt.legend(loc='best',fontsize=myfontsize,frameon=False)\n",
    "plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.ylabel('Ratio to Average',fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ [GeV/c]',fontsize=myfontsize)\n",
    "plt.ylim(ymin=0.0,ymax=2.0)\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "plt.axhline(y=1.15,color='k', alpha=0.5)\n",
    "plt.axhline(y=0.85,color='k', alpha=0.5)\n",
    "\n",
    "\n",
    "#ax.fill_between(bincenters+binwidth,0.85,1.15,alpha=0.2, label='15% Syst uncertainty',color='black')\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('SpectraRatio_%s.pdf'%dataFiles[0])\n",
    "\n",
    "#################\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "\n",
    "for varkey in ['NN','Emax','Lambda']:\n",
    "    \n",
    "    plt.errorbar(bincenters,np.divide(purity[varkey],purity['Lambda']), xerr = binwidth,   yerr=np.divide(purityError[varkey],purity['Lambda']),\n",
    "                 label=label[varkey], linestyle=\"None\", marker='o', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.legend(loc='best',fontsize=myfontsize,frameon=False)\n",
    "plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.ylabel('Ratio to Lambda ',fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ (GeV/c)',fontsize=myfontsize)\n",
    "plt.ylim(ymin=0.0,ymax=2.0)\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "plt.axhline(y=1.05,color='k', alpha=0.5)\n",
    "plt.axhline(y=0.95,color='k', alpha=0.5)\n",
    "\n",
    "#ax.fill_between(bincenters+binwidth,0.85,1.15,alpha=0.2, label='15% Syst uncertainty',color='black')\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('PurityRatio%s.pdf'%dataFiles[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "\n",
    "\n",
    "for varkey in ['NN','Emax','Lambda']:\n",
    "    \n",
    "    plt.errorbar(bincenters, chi2perdof[varkey], xerr = binwidth, label=label[varkey], marker='o')\n",
    "\n",
    "    \n",
    "plt.legend(loc='best',fontsize=myfontsize,frameon=False)\n",
    "plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.ylabel('Chi2 per dof',fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ [GeV/c]',fontsize=myfontsize)\n",
    "plt.ylim(ymin=0.0,ymax=3.0)\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "plt.ylim(ymin=0.0)\n",
    "#ax.fill_between(bincenters,0.85,1.15,alpha=0.2, label='15% Syst uncertainty',color='black')\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('Chi2_%s.pdf'%dataFiles[0])\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "\n",
    "plt.errorbar(bincenters,purity['Lambda'], xerr = binwidth, yerr = purityError[varkey], label='Template fit', linestyle=\"None\", alpha=0.9, marker='o')\n",
    "ax.fill_between(bincenters,puritySysDo['Lambda'],puritySysUp['Lambda'],alpha=0.2)\n",
    "\n",
    "#plt.errorbar(bincenters,purity['LambdaAngle'], xerr = binwidth, yerr = purityError[varkey], label='Template fit, angle', linestyle=\"None\", alpha=0.9, marker='o')\n",
    "#ax.fill_between(bincenters,puritySysDo['LambdaAngle'],puritySysUp['LambdaAngle'],alpha=0.2)\n",
    "\n",
    "    #plt.errorbar(bincenters,purity[varkey], xerr = binwidth, yerr = systematic, label=varkey, linestyle=\"None\", alpha=0.3, marker='o')\n",
    "\n",
    "    \n",
    "x = np.array([11,13,15,17,19,22.5,27.5,35.0,50])\n",
    "y = np.array([0.193191, 0.277126, 0.325119, 0.381229, 0.450115, 0.491837, 0.521378, 0.546777, 0.643158])\n",
    "\n",
    "\n",
    "ystat = np.array([0.0224782, 0.0316375, 0.043516,0.0189481, 0.0227371, 0.0196182, 0.0298453, 0.0347046, 0.0468214])\n",
    "ysys = np.array([0.021847, 0.0282663, 0.0388568, 0.0355463, 0.0403336, 0.0444923, 0.0493448, 0.0542536, 0.0605971])\n",
    "\n",
    "ydo = [a - b for a, b in zip(y, ysys)]\n",
    "yup = [a + b for a, b in zip(y, ysys)]\n",
    "\n",
    "xerror = [1,1,1,1,1,2.5,2.5,5,10]\n",
    "\n",
    "plt.errorbar(x, y, xerr=xerror, yerr=ystat, marker='o',  linestyle=\"None\", alpha=0.65, label='ABCD method')\n",
    "ax.fill_between(x, ydo, yup ,alpha=0.2)\n",
    "\n",
    "\n",
    "plt.ylabel('Purity', fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ (GeV/c)',fontsize=myfontsize)\n",
    "plt.ylim(ymin=0.0,ymax=1.0)\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "\n",
    "plt.legend(loc='best',fontsize=myfontsize,frameon=False)\n",
    "plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('purity_ABCD_%s.pdf'%dataFiles[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "\n",
    "for varkey in ['NN','Emax','Lambda']:\n",
    "    plt.errorbar(bincenters,purity[varkey], xerr = binwidth, yerr = purityError[varkey], label=label[varkey], \n",
    "                 linestyle=\"None\", alpha=0.9, marker='o')\n",
    "    ax.fill_between(bincenters,puritySysDo[varkey],puritySysUp[varkey],alpha=0.2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "plt.xlim(xmin=12.0,xmax=xmaximo)\n",
    "plt.ylabel('Purity', fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ (GeV/c)',fontsize=myfontsize)\n",
    "plt.ylim(ymin=0.0,ymax=.85)\n",
    "legend = plt.legend(loc='upper left',fontsize=18,frameon=False,title='ALICE Performance\\n 5 TeV p-Pb')\n",
    "plt.setp(legend.get_title(),fontsize=20)\n",
    "\n",
    "#plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('purity_Comparison_%s.pdf'%dataFiles[0])\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "for varkey in ['NN','Emax','Lambda']:\n",
    "    plt.errorbar(bincenters,efficiency[varkey], xerr = binwidth,  label=label[varkey], linestyle=\"None\", marker='o')\n",
    "plt.ylim(ymin=0.0,ymax=1.0)\n",
    "plt.legend(loc='best',fontsize=myfontsize,frameon=False)\n",
    "plt.title(dataname ,fontsize=myfontsize)\n",
    "plt.xlim(xmin=12,xmax=xmaximo)\n",
    "plt.ylabel('Shower-shape cut efficiency', fontsize=myfontsize)\n",
    "plt.xlabel(r'cluster $p_{\\mathrm{T}}$ [GeV/c]',fontsize=myfontsize)\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('ShowerShapeEfficiency_%s.pdf'%dataFiles[0])\n",
    "\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "plt.subplot(1,3,1)\n",
    "\n",
    "plt.errorbar(bincenters,purity['Lambda'], xerr = binwidth, yerr = purityError[varkey], label='Template fit', linestyle=\"None\", alpha=0.9, marker='o')\n",
    "plt.errorbar(bincenters, purity_bkgonlymethod['Lambda'], xerr = binwidth, label='Template fit', alpha=0.9, linestyle=\"None\",marker='*')\n",
    "plt.ylim(ymin=0.0,ymax=1.0)\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.errorbar(bincenters,purity['NN'], xerr = binwidth, yerr = purityError[varkey], label='Template fit', linestyle=\"None\", alpha=0.9, marker='o')\n",
    "plt.errorbar(bincenters, purity_bkgonlymethod['NN'], xerr = binwidth, label='Template fit', alpha=0.9,linestyle=\"None\", marker='*')\n",
    "plt.ylim(ymin=0.0,ymax=1.0)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.errorbar(bincenters,purity['Emax'], xerr = binwidth, yerr = purityError[varkey], label='Template fit', linestyle=\"None\", alpha=0.9, marker='o')\n",
    "plt.errorbar(bincenters, purity_bkgonlymethod['Emax'], xerr = binwidth, label='Template fit',linestyle=\"None\", alpha=0.9, marker='*')\n",
    "\n",
    "\n",
    "plt.ylim(ymin=0.0,ymax=1.0)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "print purity['Lambda']\n",
    "print purity_bkgonlymethod['Lambda']\n",
    "\n",
    "#plt.clf()\n",
    "#plt.errorbar(bincenters,np.diff(), xerr = binwidth, yerr = purityError[varkey], label='Template fit', linestyle=\"None\", alpha=0.9, marker='o')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'xtick.labelsize': 16}) \n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "\n",
    "print bincenters\n",
    "bins = np.append(bincenters, 40)\n",
    "\n",
    "print bins\n",
    "\n",
    "ax.fill_between(bins,np.append(puritySysDo['Lambda'],puritySysDo['Lambda'][-1]) ,np.append(puritySysUp['Lambda'],puritySysUp['Lambda'][-1]),\n",
    "                alpha=0.2,label='Syst. Error', color='k',linestyle=\"None\", edgecolor=\"None\",lw=0)\n",
    "#ax.fill_between([35.0179,40],puritySysDo['Lambda'][-1],puritySysUp['Lambda'][-1],alpha=0.2,color='k',linestyle=\"None\", edgecolor=\"None\", lw=0)\n",
    "\n",
    "print purityError['Lambda']\n",
    "\n",
    "plt.errorbar(bincenters,purity['Lambda'], xerr = binwidth, yerr = purityError['Lambda'], label='Stat. Error', \n",
    "             linestyle=\"None\", alpha=0.9, marker='o',color='k',markersize=6)\n",
    "\n",
    "\n",
    "plt.ylabel('Purity', fontsize=myfontsize)\n",
    "plt.xlabel(r'$p_{\\mathrm{T}}$ (GeV/$c$)',fontsize=myfontsize)\n",
    "plt.ylim(ymin=0.0,ymax=.72)\n",
    "legend = plt.legend(loc='upper left',fontsize=18,frameon=False,title='ALICE Performance\\n p-Pb $\\sqrt{s_{\\mathrm{NN}}}$ = 5 TeV')\n",
    "plt.setp(legend.get_title(),fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('PurityPlot_%s.pdf'%dataFiles[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tag = dataFiles[0].split('_small')[0]+mcSignal_Files[0].split('_small')[0]+isolation\n",
    "#binedges = [15.0, 16.0,17.0,18.0,20.0,22.5,25.0]#,60.0] # [16.0,17.0,18.0,19.0,20.0,22.0,24.0,25.0,30.0,40.0,60.0]\n",
    "binedges = [13,14]\n",
    "bincenters = np.array([(hedge+ledge)/2.0 for ledge, hedge in zip(binedges[:-1], binedges[1:])])\n",
    "binwidth = np.array([abs(hedge-ledge)/2.0 for ledge, hedge in zip(binedges[:-1], binedges[1:])])\n",
    "\n",
    "PerSuperModule = False\n",
    "nsupermodules = 20\n",
    "SplitEta       = False\n",
    "cutbadSM      = False\n",
    "\n",
    "varkey = 'Lambda'\n",
    "bins = 80\n",
    "fitRange = fitRange_dic[varkey]\n",
    "xlabel = xlabel_dic[varkey] \n",
    "varname = varname_dic[varkey] \n",
    "limit_yaxis = limit_yaxis_dic[varkey] \n",
    "\n",
    "puritymin = puritymin_dic[varkey] \n",
    "puritymax =  puritymax_dic[varkey] \n",
    "fitRangeBKGonly=fitRangeBKGonly_dic[varkey] \n",
    "Range=Range_dic[varkey] \n",
    "\n",
    "for ipt in range(len(binedges)-1):\n",
    "    ptmin = binedges[ipt]\n",
    "    ptmax = binedges[ipt+1]\n",
    "    title = r'%2.1f < $p_{T}$ < %2.1f GeV'%(ptmin, ptmax)\n",
    "    maskpt_do = dataHists.cluster_pt>ptmin\n",
    "    maskpt_up = dataHists.cluster_pt<ptmax\n",
    "    maskdata = maskpt_do & maskpt_up \n",
    "\n",
    "    mcmaskpt_do = mcSignal_Hists.cluster_pt>ptmin\n",
    "    mcmaskpt_up = mcSignal_Hists.cluster_pt<ptmax  \n",
    "    maskmc   = mcmaskpt_do & mcmaskpt_up\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Templates = getTemplates(dataHists[maskdata], mcSignal_Hists[maskmc], bins,  isocut=isomax, nonisocuts=nonisorange, \n",
    "                             var = varname,  varRange=Range, isovar=isolation)\n",
    "    dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "    tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, fitRange=fitRange)\n",
    "    tf.plotFit(xlabel, title, True, puritymin, puritymax,\n",
    "               normalize=False, \n",
    "               figureFilename=varname+'ptmin%2.0f_ptmax%2.0f_%s_Iso%2.0f_Noniso%2.0f_%2.0f.pdf'%(ptmin,ptmax,tag,isomax, nonisorange[0],nonisorange[1]))\n",
    "   \n",
    "    ##get purity\n",
    "    purity, pmin, pmax = tf.getPurity(puritymin, puritymax)\n",
    "    puritylow = 0\n",
    "    purityhigh = 0\n",
    "    print 'ptmin = %2.2f; ptmax =%2.2f // purity %2.2f =/- %2.2f'%(ptmin, ptmax, purity,  max(abs(purity-puritylow), abs(purity-purityhigh) ))\n",
    "    purityarreglo.append(purity)\n",
    "    purityErrorarreglo.append( max(abs(purity-puritylow), abs(purity-purityhigh) ))\n",
    "    if(cutbadSM):\n",
    "        dataveto = dataHists.cluster_SuperModule!=3\n",
    "        dataveto2 = dataHists.cluster_SuperModule!=7\n",
    "        mcveto =  mcSignal_Hists.cluster_SuperModule!=3\n",
    "        mcveto2 =  mcSignal_Hists.cluster_SuperModule!=7\n",
    "\n",
    "        Templates = getTemplates(dataHists[maskdata & dataveto & dataveto2],\n",
    "                                 mcSignal_Hists[maskmc & mcveto & mcveto2], \n",
    "                                 bins,  isocut=isomax, nonisocuts=nonisorange, var = varname,  varRange=Range, isovar=isolation)\n",
    "        dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, fitRange=fitRange)\n",
    "        tf.plotFit(xlabel, title, True, puritymin, puritymax,\n",
    "                   normalize=False, figureFilename=varname+'NoSM3or7_ptmin%2.0f_ptmax%2.0f_%s_Iso_%1.0f_Noniso_%1.0f_%2.0f.pdf'%(ptmin,ptmax,tag,isomax, nonisorange[0],nonisorange[1]))\n",
    "    \n",
    "    \n",
    "    maskseta_data = [dataHists.cluster_eta>0, dataHists.cluster_eta<0]\n",
    "    maskseta_mc   = [mcSignal_Hists.cluster_eta>0, mcSignal_Hists.cluster_eta<0]\n",
    "   \n",
    "    if SplitEta:\n",
    "        for ieta in range(2):\n",
    "            Templates = getTemplates(dataHists[maskdata & maskseta_data[ieta]], mcSignal_Hists[maskmc & maskseta_mc[ieta]], bins, \n",
    "                                     isocut=isomax, nonisocuts=nonisorange, var = varname,  varRange=Range, isovar=isolation)\n",
    "            dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "            tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, fitRange=fitRange)\n",
    "            tf.plotFit(xlabel, title, True, puritymin, puritymax,normalize=False,\n",
    "                       figureFilename=varname+'Eta_%d_ptmin%2.0f_ptmax%2.0f_%s_Iso_%1.0f_Noniso_%1.0f_%2.0f.pdf'%(ieta,ptmin,ptmax,tag,isomax, nonisorange[0],nonisorange[1]))\n",
    "    \n",
    "    \n",
    "    if(PerSuperModule):\n",
    "        purityarray = []\n",
    "        purityerrarray = []\n",
    "\n",
    "        purityarrayVeto = []\n",
    "        \n",
    "        farray = []\n",
    "        farrayVeto = []\n",
    "        fErrarray = []\n",
    "        fErrarrayVeto = []\n",
    "        \n",
    "        chi2 = []\n",
    "        chi2Veto = [] \n",
    "        bins = 200\n",
    "        fig = plt.figure(figsize=(24,24))\n",
    "        for ism in range(nsupermodules ):\n",
    "            masksm = dataHists.cluster_SuperModule==ism\n",
    "            plt.subplot(2,nsupermodules/2 ,ism+1)\n",
    "            plt.hist2d(dataHists[maskdata & masksm].cluster_eta, dataHists[maskdata &masksm].cluster_phi,range=([-.70, .70], \n",
    "                       [-np.pi, np.pi]),bins=100)\n",
    "        plt.show()\n",
    "        #fig.tight_layout()\n",
    "        fig.savefig('supermodules.png')\n",
    "        for ism in range(nsupermodules):\n",
    "            mask_supermodules_data = dataHists.cluster_SuperModule==ism\n",
    "            mask_supermodules_mc   = mcSignal_Hists.cluster_SuperModule==ism\n",
    "            maskdata_sm = maskdata & mask_supermodules_data\n",
    "            maskmc_sm  = maskmc & mask_supermodules_mc\n",
    "        \n",
    "            bins = 120 #was 80\n",
    "            Templates = getTemplates(dataHists[maskdata_sm], mcSignal_Hists[maskmc_sm], bins,  isocut=isomax, nonisocuts=nonisorange, \n",
    "                                     var = varname,  varRange=Range, isovar=isolation)\n",
    "            dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "            tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges,\n",
    "                             verbosity=0, fitRange=fitRange)\n",
    "\n",
    "            tf.plotFit(xlabel, title, True, puritymin, puritymax, normalize=False,\n",
    "                       figureFilename=varname+'SuperModule%d_ptmin%2.0f_ptmax%2.0f_%s_Iso_%1.0f_Noniso_%1.0f_%2.0f.pdf'%(ism,ptmin,ptmax,tag,isomax, nonisorange[0],nonisorange[1]))\n",
    "        \n",
    "            #Everything EXCEPT the SM = ism\n",
    "            purity, pmin, pmax = tf.getPurity(puritymin, puritymax)\n",
    "            puritylow = 0\n",
    "            purityhigh = 0\n",
    "            \n",
    "            purityarray.append(purity)\n",
    "            purityerrarray.append(max(abs(purity-puritylow), abs(purity-purityhigh) ))\n",
    "            farray.append(tf.fitNsig)\n",
    "            fErrarray.append(tf.fitNsigerr)\n",
    "            chi2.append(tf.chi2/tf.dof)\n",
    "            \n",
    "            bins = 120\n",
    "            mask_supermodules_data = dataHists.cluster_SuperModule!=ism\n",
    "            mask_supermodules_mc   = mcSignal_Hists.cluster_SuperModule!=ism\n",
    "            maskdata_sm = maskdata & mask_supermodules_data\n",
    "            maskmc_sm  = maskmc & mask_supermodules_mc\n",
    "            \n",
    "            Templates = getTemplates(dataHists[maskdata_sm], mcSignal_Hists[maskmc_sm], bins,  isocut=isomax, nonisocuts=nonisorange,\n",
    "                                     var = varname,  varRange=Range, isovar=isolation)\n",
    "            dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "            tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, \n",
    "                              verbosity=0, fitRange=fitRange)\n",
    "            tf.plotFit(xlabel, title, True, puritymin, puritymax, normalize=False,\n",
    "                       figureFilename=varname+'VetoSuperModule%d_ptmin%2.0f_ptmax%2.0f_%s_Iso_%1.0f_Noniso_%1.0f_%2.0f.pdf'%(ism,ptmin,ptmax,tag,isomax, nonisorange[0],nonisorange[1]))\n",
    "            purity, pmin, pmax = tf.getPurity(puritymin, puritymax)\n",
    "\n",
    "            purityarrayVeto.append(purity)\n",
    "            \n",
    "            farrayVeto.append(tf.fitNsig)\n",
    "            fErrarrayVeto.append(tf.fitNsigerr)\n",
    "            chi2Veto.append(tf.chi2/tf.dof)\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "     \n",
    "            \n",
    "        fig = plt.figure(figsize=(12,3))\n",
    "        plt.subplot(121)\n",
    "        \n",
    "        plt.plot(range(nsupermodules),purityarrayVeto, marker='o')\n",
    "        plt.ylim([0.0,1.0])\n",
    "        \n",
    "        if 'NN' in varname:\n",
    "            ylabel = 'Purity with DNN fit'\n",
    "        else:\n",
    "            ylabel = 'Purity with Lambda fit'\n",
    "            \n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel('Removed Supermodule #')\n",
    "        plt.axhline(y=np.average(purityarrayVeto),color='r',label='Average =%2.1f%%'%(100.0*np.average(purityarrayVeto)))\n",
    "        plt.legend(title=dataname, loc='best')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.errorbar(range(nsupermodules),purityarray, yerr=purityerrarray, linestyle=\"None\", marker='o')\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel('Supermodule #')\n",
    "        plt.axhline(y=np.average(purityarray),color='r',label='Average =%2.1f%%'%(100.0*np.average(purityarray)))\n",
    "        plt.axhspan(np.average(purityarray)-np.std(purityarray), \n",
    "                    np.average(purityarray)+np.std(purityarray),\n",
    "                    color='r',\n",
    "                    label='+/- RMS =%2.1f'%(100.0*np.std(purityarray)), alpha=0.4)\n",
    "        plt.legend(title=dataname, loc='best')\n",
    "\n",
    "        print 'PURITY RMS = ' , np.std(purityarray)\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig('SuperModules_SummaryPurity'+varname+tag+'.pdf')\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.plot(range(nsupermodules),chi2Veto, marker='o')\n",
    "        plt.ylim([0.0,3.0])\n",
    "        plt.ylabel('Chi2/dof')\n",
    "        plt.xlabel('Removed Supermodule #')\n",
    "        plt.axhline(y=np.average(chi2Veto),color='r',label='Average')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(range(nsupermodules),chi2, marker='o')\n",
    "        plt.ylim([0.0,3.0])\n",
    "        plt.ylabel('Chi2/dof')\n",
    "        plt.xlabel('Supermodule #')\n",
    "        plt.axhline(y=np.average(chi2),color='r',label='Average')\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        fig.savefig('SuperModules_SummaryPurity'+varname+tag+'.pdf')\n",
    "   \n",
    "\n",
    "\n",
    "              \n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        plt.subplot(121)\n",
    "        \n",
    "        plt.errorbar(range(nsupermodules),farrayVeto, yerr=fErrarrayVeto,marker='o')\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.ylabel('Fraction')\n",
    "        plt.xlabel('Removed Supermodule #')\n",
    "        plt.axhline(y=np.average(farrayVeto),color='r',label='Average')\n",
    "       # plt.show()\n",
    "        #fig.savefig('supermodulesVetoFraction.png')   \n",
    "\n",
    "        plt.subplot(122)\n",
    "        #fig = plt.figure(figsize=(12,12))\n",
    "        plt.errorbar(range(nsupermodules),farray, yerr=fErrarray,marker='o')\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.ylabel('Fraction')\n",
    "        plt.xlabel('Supermodule #')\n",
    "        plt.axhline(y=np.average(farray),color='r',label='Average')\n",
    "        plt.show()\n",
    "        fig.savefig('SummaryFraction'+varname+tag+'.png')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "print purityarreglo\n",
    "print purityErrorarreglo\n",
    "\n",
    "\n",
    "\n",
    "x = [11,13,15,17,19,22.5,27.5,35.0,50]\n",
    "y = [0.193191, 0.277126, 0.325119, 0.381229, 0.450115, 0.491837, 0.521378, 0.546777, 0.643158]\n",
    "yerror = [0.0224782, 0.0316375,0.043516, 0.0189481, 0.0227371, 0.0196182, 0.0298453, 0.0347046, 0.0468214]\n",
    "xerror = [1,1,1,1,1,2.5,2.5,5,10]\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.errorbar(bincenters,purityarreglo, xerr=binwidth, yerr=purityErrorarreglo, alpha=0.5, color='black', linestyle=\"None\", marker='o', label='Template Fit')\n",
    "plt.errorbar(x, y, xerr=xerror, yerr=yerror, marker='o',  linestyle=\"None\", alpha=0.4, label='ABCD method')\n",
    "plt.ylim([0.0,1.00])\n",
    "plt.xlim([10.0, 62.0])\n",
    "plt.ylabel('Purity')\n",
    "plt.xlabel(r'$p_{T}$ [GeV/c]')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('Purity_'+varname+tag+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bincenters, [0.33324522, 0.29435754, 0.2948806, 0.43981975, 0.52505141, 0.55698127, 0.52820379, 0.52450752])\n",
    "plt.plot(bincenters, [0.44355085, 0.44128826, 0.47394377, 0.5392772, 0.5766626, 0.62544429, 0.59503043, 0.60428977])\n",
    "plt.plot(bincenters, [0.39109263, 0.34360024, 0.31159431, 0.47637609, 0.48879293, 0.53994912, 0.48959836, 0.5494228])\n",
    "#plt.plot([11,13,15,17,19,22.5,27.5,35.0,50], [0.193191, 0.277126, 0.325119, 0.381229, 0.450115, 0.491837, 0.521378, 0.546777, 0.643158])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.plotTemplates(xlabel,'Templates_'+varname+'_'+tag+'.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on test data, including bkg only fit to bkg dominated region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bins = 50 #75\n",
    "\n",
    "#nonisoranges=[(3.0,10.0), (2.0,10.0), (4.0,10.0), (3,15.0), (2.0,15.0), (4.0,15.0)]\n",
    "nonisoranges = [(4.0,10.0)]\n",
    "for nonisorange in nonisoranges:\n",
    "    #binedges = [10.0, 11.0,13.0,16.0]\n",
    "    binedges = [20.0,30.0]\n",
    "    for ipt in range(len(binedges)-1):\n",
    "        ptmin = binedges[ipt]\n",
    "        ptmax = binedges[ipt+1]\n",
    "    \n",
    "        maskpt_do = dataHists.cluster_pt>ptmin\n",
    "        maskpt_up = dataHists.cluster_pt<ptmax\n",
    "        maskdata = maskpt_do & maskpt_up \n",
    "\n",
    "        mcmaskpt_do = mcSignal_Hists.cluster_pt>ptmin\n",
    "        mcmaskpt_up = mcSignal_Hists.cluster_pt<ptmax  \n",
    "        maskmc   = mcmaskpt_do & mcmaskpt_up\n",
    "    \n",
    "        title = r'%2.1f < $p_{\\mathrm{T}}$ < %2.1f GeV'%(ptmin, ptmax)\n",
    "        Templates = getTemplates(dataHists[maskdata], mcSignal_Hists[maskmc], bins,  isocut=isomax, nonisocuts=nonisorange,\n",
    "                             var = varname, varRange=Range, isovar=isolation)\n",
    "        dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "    #fit normally in the entire fit range\n",
    "        #fitRange=(0.0, 1.0)\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, fitRange=fitRange)\n",
    "        tf.plotFit(xlabel, title, True, puritymin, puritymax, normalize=False,figureFilename=varname+'ptmin%2.0f_ptmax%2.0f_%s_Iso_%2.0f_Noniso%2.0f_%2.0f.pdf'%(ptmin,ptmax,tag,10.0*isomax, 10.0*nonisorange[0],10.0*nonisorange[1]))\n",
    "        #fit with N float and f=0 fixed in bkg dominated region\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, fitRange=fitRangeBKGonly, fixN=False,fixNsig=True,Nsig0=0.0)\n",
    "        tf.plotFit(xlabel, title, False, puritymin, puritymax, normalize=False,figureFilename=varname+'ptmin%2.0f_ptmax%2.0f_%s_Iso_%2.0f_Noniso%2.0f_%2.0f_BKGONLYFIT.pdf'%(ptmin,ptmax,tag,10.0*isomax, 10.0*nonisorange[0],10.0*nonisorange[1]))\n",
    "\n",
    "    #tf.plotResiduals(varname,'residualBKGOnly.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON between DATA and MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "plt.subplot(3,3,1)\n",
    "\n",
    "#nonisorange = 'cluster_iso_its_04_sub>5.0 and cluster_iso_its_04_sub<10.0'\n",
    "nonisorange = 'cluster_iso_its_new>5.0 and cluster_iso_its_new<10.0 '\n",
    "isorange    = 'cluster_iso_its_new<1.5'\n",
    "\n",
    "plt.hist(dataHists.query(isorange)['cluster_pt'],range=(0,60), bins=100,histtype='step', normed=True, label='data')\n",
    "plt.hist(mcSignal_Hists.query(isorange)['cluster_pt'],range=(0,60), bins=100,histtype='step',color ='purple', normed=True,\n",
    "         weights=mcSignal_Hists.query(isorange)['weights'],label='signalMC')\n",
    "#plt.hist(mcSignal_Hists['cluster_pt'],range=(10,16), bins=10,histtype='step', normed=True)\n",
    "\n",
    "plt.legend()\n",
    "netabins = 20\n",
    "plt.subplot(3,3,2)\n",
    "plt.hist(dataHists['cluster_eta'],range=(-1.0,1.0), bins=netabins,histtype='step', normed=True)\n",
    "plt.hist(dataHists.query('cluster_iso_its_04<1.0')['cluster_eta'],range=(-1.0,1.0), bins=netabins,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists['cluster_eta'],range=(-1.0,1.0), bins=netabins,color ='purple', histtype='step', normed=True, weights=mcSignal_Hists['weights'])\n",
    "\n",
    "nphibins = 20\n",
    "plt.subplot(3,3,3)\n",
    "plt.hist(dataHists['cluster_phi'],range=(-np.pi,np.pi), bins=nphibins,histtype='step', normed=True)\n",
    "plt.hist(dataHists.query('cluster_iso_its_04<1.0')['cluster_phi'],range=(-np.pi,np.pi), bins=nphibins,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists['cluster_phi'],range=(-np.pi,np.pi), bins=nphibins,color ='purple', histtype='step', normed=True, weights=mcSignal_Hists['weights'])\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "\n",
    "plt.hist(dataHists['cluster_pt'],range=(0,50), bins=100,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists['cluster_pt'],range=(0,50), bins=100,histtype='step',color ='purple', normed=True,\n",
    "         weights=mcSignal_Hists['weights'])\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "plt.hist(dataHists.query(nonisorange)['cluster_NN1'],range=(0,1.0), \n",
    "         bins=50,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists.query(nonisorange)['cluster_NN1'],range=(0,1.0), \n",
    "         bins=50,histtype='step',color ='purple', normed=True,weights=mcSignal_Hists.query(nonisorange)['weights'])\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "plt.hist(dataHists['cluster_Lambda'],range=(0,2.0), bins=50,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists['cluster_Lambda'],range=(0,2.0), bins=50,histtype='step',color ='purple', normed=True,weights=mcSignal_Hists['weights'])\n",
    "\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "plt.hist(dataHists['weights'],range=(-2,2), bins=100, normed=True)\n",
    "plt.hist(mcSignal_Hists['weights'],range=(-2,2), bins=100,histtype='step',color ='purple', \n",
    "         normed=True, weights=mcSignal_Hists['weights'])\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "plt.hist(dataHists['cluster_iso_its_04_sub'],range=(-5,30.0), bins=70,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists['cluster_iso_its_04_sub'],range=(-5,30.0), bins=70,histtype='step',color ='purple', \n",
    "         normed=True, weights=mcSignal_Hists['weights'])\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,3,9)\n",
    "plt.hist(dataHists['ue_estimate_its_const'],range=(-5,30.0), bins=70,histtype='step', normed=True)\n",
    "plt.hist(mcSignal_Hists['ue_estimate_its_const'],range=(-5,30.0), bins=70,histtype='step',color ='purple', \n",
    "         normed=True, weights=mcSignal_Hists['weights'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHOWER SHAPES FOR SIGNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(mcSignal_Hists['cluster_NN1'], bins=50,range=(0,1.0), color='black',histtype='step', normed=True,\n",
    "        weights=mcSignal_Hists['weights'])\n",
    "plt.xlabel('Deep Neural Network', fontsize=13)\n",
    "plt.ylabel('normalized units')\n",
    "\n",
    "    \n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(mcSignal_Hists['cluster_emax_over_e'], bins=50,range=(0,1.0), normed=True,\n",
    "             color='black', histtype='step',weights=mcSignal_Hists['weights'])\n",
    "plt.xlabel(r'$E_{max}/E_{cluster}$',fontsize=14)\n",
    "plt.ylabel('normalized units')\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(mcSignal_Hists['cluster_Lambda'], bins=50,range=(0,1.0), normed=True,\n",
    "             color='black', histtype='step',weights=mcSignal_Hists['weights'])\n",
    "plt.xlabel(r'$\\sigma_{long}^{2}$', fontsize=14)\n",
    "plt.ylabel('normalized units')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('ShowerShapeVariables_IsoClusters_%s.pdf'%name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIGNAL MC ISOLATION DISTRIBUTION and UE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "#nonisorange = 'cluster_iso_its_04_sub>5.0 and cluster_iso_its_04_sub<10.0'\n",
    "nonisorange = 'cluster_iso_its_04_sub>5.0 and cluster_iso_its_04_sub<10.0 and cluster_pt<30'\n",
    "isorange    = 'cluster_iso_its_04_sub<1.5.0 and cluster_iso_truth<3.0 and cluster_pt<30'\n",
    "\n",
    "plt.hist(mcSignal_Hists.query('cluster_pt<20')['cluster_iso_its_04_sub'],normed=True, label='Gamma-jet MC', range=(-30,30.0), bins=200,histtype='step', color='black',\n",
    "          weights=mcSignal_Hists.query('cluster_pt<20')['weights'])\n",
    "plt.hist(mcBKG_Hists['cluster_iso_its_04_sub'],normed=True, label='Dijet MC', range=(-30,30.0), bins=200,histtype='step',\n",
    "          weights=mcBKG_Hists['weights'])\n",
    "\n",
    "plt.legend(loc='best',fontsize=12,frameon=False)\n",
    "\n",
    "plt.xlabel('Cluster Isolation [GeV]',fontsize=15)\n",
    "plt.ylabel('arb units',fontsize=15)\n",
    "\n",
    "#plt.axvline(x=1.0,color='g',alpha=0.7)\n",
    "\n",
    "#plt.axvline(x=3.0,color='r',alpha=0.7)\n",
    "\n",
    "#plt.hist(mcSignal_Hists['cluster_iso_its_04'],range=(-10,10.0), bins=60,histtype='step', \n",
    "#         weights=mcSignal_Hists['weights'])\n",
    "\n",
    "\n",
    "\n",
    "#plt.hist(mcSignal_Hists['cluster_frixione_its_04_02'],range=(-10,10.0), bins=60,histtype='step', \n",
    "#         weights=mcSignal_Hists['weights'])\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.hist(mcSignal_Hists['cluster_iso_its_04_sub'],cumulative=True, color='black', normed=True, range=(-10,30.0), bins=200,histtype='step', \n",
    "          weights=mcSignal_Hists['weights'], label='Gamma-jet MC')\n",
    "plt.hist(mcBKG_Hists['cluster_iso_its_04_sub'],cumulative=True, normed=True, range=(-10,30.0), bins=200,histtype='step', \n",
    "          weights=mcBKG_Hists['weights'], label='Dijet MC')\n",
    "\n",
    "plt.xlabel('Cluster Isolation [GeV]',fontsize=15)\n",
    "plt.ylabel('Cumulative probability',fontsize=15)\n",
    "#plt.legend(loc='best',fontsize=12,frameon=False)\n",
    "\n",
    "plt.axvline(x=1.5,color='g',alpha=0.7)\n",
    "\n",
    "plt.axvline(x=4.0,color='r',alpha=0.7)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('IsolationMCsignal_%s.pdf'%mcSignal_Files[0].split('_small')[0])\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.hist(mcSignal_Hists['ue_estimate_its_const'],range=(-10,10.0), label='MC signal', bins=100,histtype='step', \n",
    "         normed=True, weights=mcSignal_Hists['weights'])\n",
    "\n",
    "plt.hist(dataHists['ue_estimate_its_const'],range=(-10,10.0), bins=100, label = 'data' , histtype='step',color ='purple', \n",
    "         normed=True)\n",
    "\n",
    "plt.hist(mcBKG_Hists['ue_estimate_its_const'],range=(-10,10.0), bins=100, label = 'MC BKG' , histtype='step',\n",
    "         normed=True, weights=mcBKG_Hists['weights'])\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "print np.average(mcSignal_Hists.query('ue_estimate_its_const<100')['ue_estimate_its_const'])\n",
    "print np.std(mcSignal_Hists.query('ue_estimate_its_const<100')['ue_estimate_its_const'])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.hist(mcSignal_Hists['cluster_isHardPhoton'],range=(-10,10.0), bins=30,histtype='step',color ='purple', \n",
    "         normed=True, weights=mcSignal_Hists['weights'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "test = dataHists\n",
    "#test = test.query('cluster_pt<16 and cluster_pt>10')\n",
    "testiso = test.query('cluster_iso_its_04_sub<1.0')\n",
    "\n",
    "plt.subplot(2,2,1) \n",
    "\n",
    "A, x, _ = plt.hist(test['cluster_phi'], range=(-np.pi, np.pi), bins=30, histtype='step')\n",
    "B, x, _ = plt.hist(testiso['cluster_phi'], range=(-np.pi, np.pi), bins=30, histtype='step')\n",
    "\n",
    "plt.subplot(2,2,2) \n",
    "\n",
    "AB = np.divide(B,A)\n",
    "\n",
    "x= np.delete(x,-1)\n",
    "x = np.add( x, (x[1]-x[0])/2.0 )\n",
    "plt.scatter(x, AB)\n",
    "plt.xlabel(r'cluster $\\phi$')\n",
    "plt.ylim(ymin=0.0,ymax=0.50)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,2,3) \n",
    "\n",
    "\n",
    "A, x, _ = plt.hist(test['cluster_eta'], range=(-1.0, 1.0), bins=20, histtype='step')\n",
    "B, x, _ = plt.hist(testiso['cluster_eta'], range=(-1.0, 1.0), bins=20, histtype='step')\n",
    "\n",
    "plt.subplot(2,2,4) \n",
    "\n",
    "AB = np.divide(B,A)\n",
    "\n",
    "x= np.delete(x,-1)\n",
    "x = np.add( x, (x[1]-x[0])/2.0 )\n",
    "plt.scatter(x, AB)\n",
    "plt.xlabel(r'cluster $\\eta$')\n",
    "plt.ylim(ymin=0.0,ymax=0.50)\n",
    "plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('IsolationFraction_%s.pdf'%dataFiles[0].split('_small')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Checking isolation distribution and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #plt.hist(dataframe['cluster_phi'], bins=50,color='black',histtype='step', normed=True)\n",
    "    #plt.xlabel(r'cluster $\\phi$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Sideband and signal region plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isotype = 'its'\n",
    "isolationvar = 'cluster_iso_%s_04' %(isotype)\n",
    "\n",
    "test = dataHists\n",
    "\n",
    "#test = test.query('cluster_pt<16 and cluster_pt>10')\n",
    "maxIso = 80.5\n",
    "minIso = -20.5\n",
    "nbins  = 101\n",
    "\n",
    "mpl.rcParams['legend.fontsize'] = 10\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "#plt.subplot(1,2,1)\n",
    "plt.hist(test['%s_raw'%isolationvar],range=(minIso,maxIso),color='red',bins=nbins,alpha=0.7,label='Raw',histtype='step')\n",
    "plt.hist(test['%s_sub'%isolationvar],range=(minIso,maxIso),bins=nbins,color='black',label='UE subtracted',histtype='step')\n",
    "#plt.hist(test['%s'%isolationvar],range=(minIso,maxIso),bins=nbins,color='red',label='UE subtracted (voronoi)',histtype='step')\n",
    "plt.xlabel('Cluster Isolation [GeV/c]',fontsize=22)\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel('Counts',fontsize=22)\n",
    "plt.legend(fontsize=16)\n",
    "plt.title(dataname, fontsize=18)\n",
    "\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.hist(test['%s_ue'%isolationvar],range=(0.0,10),bins=nbins,alpha=0.5, label='rho x area voronoi')\n",
    "#plt.hist(test['ue_estimate_its_const']*0.4*0.4*3.14,range=(0.0,10),bins=nbins,alpha=0.5, label='rho x area')\n",
    "#plt.text(5, 50000, 'UE Average = %2.1f [GeV]'%(np.average(test['%s_ue'%isolationvar])), fontsize=12)\n",
    "#plt.legend()\n",
    "#plt.text(5, 40000, 'UE Average = %2.1f [GeV]'%(np.average(test['ue_estimate_its_const*0.4*0.4*3.14'])), fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('IsolationWithUESubtraction_%s.pdf'%dataFiles[0].split('_small')[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Sideband and signal region plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build templates from dataframes\n",
    "\n",
    "mpl.rcParams.update({'xtick.labelsize': 16}) \n",
    "\n",
    "isolationvar = 'cluster_iso_its_04_sub'\n",
    "#isolationvar = 'cluster_frixione_its_04_02'\n",
    "#test = dataHists.query('%s<200'%isolationvar)\n",
    "test = dataHists\n",
    "\n",
    "#test = test.query('cluster_pt<16 and cluster_pt>10')\n",
    "\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(test[isolationvar],bins=100,range=(-35, 65),label='Data',normed=True,alpha=0.8,histtype='step',linewidth=2,color='black')\n",
    "plt.xlabel('Cluster Isolation [GeV/c]')\n",
    "plt.ylabel('Probability')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(test[isolationvar],bins=100,range=(-35, 60),label='ola', cumulative=True, normed=True,alpha=0.8,histtype='step',linewidth=2,color='black')\n",
    "plt.xlabel('Isolation Energy [GeV/c]')\n",
    "plt.ylabel('Cumulative probability')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.axvspan(-5,0.0, color='green', alpha=0.6,label='Signal region')\n",
    "\n",
    "plt.show()\n",
    "#fig.tight_layout()\n",
    "mpl.rcParams['legend.fontsize'] = 13\n",
    "\n",
    "#fig.savefig('IsolationSideband.png')\n",
    "\n",
    "#fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "\n",
    "\n",
    "#mpl.rcParams.update({'xtick.labelsize': 16}) \n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.hist(test[isolationvar],bins=200, range=(-35.5, 64.5), label=dataname,normed=True,histtype='step',linewidth=2,color='black')\n",
    "plt.xlabel(r'$ISO$ (GeV/$c$)',fontsize=18)\n",
    "plt.axvspan(-3,1.0, color='green', alpha=0.4,label='Signal region')\n",
    "plt.axvspan(5,10, color='#FDB515', alpha=0.450,label='Sideband ')\n",
    "#plt.axvspan(2,15, color='orange', alpha=0.3,label='Extended\\nsideband',hatch=\"/\")\n",
    "legend = plt.legend(loc='best',frameon=False,title='ALICE Performance',fontsize=16)\n",
    "plt.ylabel('Probability',fontsize=18)\n",
    "plt.setp(legend.get_title(),fontsize=17)\n",
    "#plt.hist(test[isolationvar],bins=181, range=(-35.5, 65.5), label='Data',normed=True,histtype='step',linewidth=2,color='black')\n",
    "\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "\n",
    "plt.xlim([-9.0,+30.0])\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('IsolationSideband_limited_%s.pdf'%dataFiles[0].split('_small')[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sideband variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test[test.cluster_frixione_its_04_02<2].hist(column='cluster_NN1',bins=40,label='ola',normed=True)\n",
    "mpl.rcParams.update({'legend.fontsize': 8})\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "\n",
    "isolationvar = 'cluster_iso_its_04_sub'\n",
    "\n",
    "test = dataHists.query('cluster_pt<30 and cluster_pt>12')\n",
    "\n",
    "\n",
    "limits =  [ (4.0,10.0), (3.0,10.0), (4.0,15.0), (3.0,15.0), (5,15)]\n",
    "nrows = 2\n",
    "ncolumns = 3\n",
    "nbins = 20\n",
    "\n",
    "\n",
    "\n",
    "mask = '%2.1f<%s<%2.1f '%(5,isolationvar, 10.0)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(test.query(mask)['cluster_emax_over_e'], range=(0,1.0), linewidth=3.0, color='black', bins=nbins,label='Nominal,5<Iso<10 GeV',\n",
    "         normed=True,alpha=0.1)#,linestyle='--')\n",
    "plt.xlabel(r'$E_{max}/E_{cluster}$', fontsize=16)\n",
    "plt.ylabel('counts ', fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(test.query(mask)['cluster_NN1'], range=(0,1.0), linewidth=3.0, color='black', bins=nbins,label='Nominal,5<Iso<10 GeV',\n",
    "         normed=True,alpha=0.1)#,linestyle='--')\n",
    "plt.xlabel('Deep Neural Network ', fontsize=16)\n",
    "plt.ylabel('counts ', fontsize=16)\n",
    "\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(test.query(mask)['cluster_Lambda'], linewidth=3.0, color='black', range=(0,1.8), bins=nbins,label='Nominal, 5<Iso<10 GeV',\n",
    "         normed=True,alpha=0.1)#,linestyle='--')\n",
    "plt.xlabel(r'$\\sigma_{long}^{2}$', fontsize=16)\n",
    "plt.ylabel('counts ', fontsize=16)\n",
    "\n",
    "for lim in limits:\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(dataname+r'  12 < $p_{T}$ < 30 GeV/c',fontsize=20)\n",
    "   # plt.xlabel(r'cluster $p_{T}$ [GeV/c]')\n",
    "\n",
    "    mask = '%2.1f<%s<%2.1f '%(lim[0],isolationvar, lim[1])\n",
    "\n",
    "    #tag = '%2.1f<Iso<%2.1f GeV'%(lim[0],lim[1])\n",
    "\n",
    "\n",
    "    tag = '%2.1f<Iso<%2.1f GeV/c'%(lim[0],lim[1])\n",
    "    plt.hist(test.query(mask)['cluster_emax_over_e'], range=(0,1.0), linewidth=1.0,bins=nbins,label=tag,normed=True,alpha=0.8,histtype='step')\n",
    "    plt.xlabel(r'$E_{max}/E_{cluster}$', fontsize=20)\n",
    "    plt.ylabel('counts ', fontsize=18)\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.hist(test.query(mask)['cluster_Lambda'],linewidth=1.0, range=(0,1.8), bins=nbins,label=tag,normed=True,alpha=0.8,histtype='step')\n",
    "    plt.xlabel(r'$\\sigma_{long}^{2}$', fontsize=20)\n",
    "    plt.ylabel('counts ', fontsize=18)\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "\n",
    "    plt.hist(test.query(mask)['cluster_NN1'], range=(0,1.0), linewidth=1.0,bins=nbins,label=tag,normed=True,alpha=0.8,histtype='step')\n",
    "    plt.xlabel('Deep Neural Network ', fontsize=20)\n",
    "    plt.ylabel('counts ', fontsize=18)\n",
    "\n",
    "\n",
    "plt.legend( fontsize=15,frameon=False)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('IsolationCorrelation%s.pdf'%dataFiles[0].split('_small')[0])\n",
    "\n",
    "test = test.query('%s>1'%isolationvar)\n",
    "\n",
    "print ' Correlation coefficients: '\n",
    "print '%20s %2.2f'%('Iso and pt',test[isolationvar].corr(test['cluster_pt']))\n",
    "print '%20s %2.2f'%('Iso and NN1',test[isolationvar].corr(test['cluster_NN1']))\n",
    "print '%20s %2.2f'%('Iso and Lambda',test[isolationvar].corr(test['cluster_Lambda']))\n",
    "\n",
    "\n",
    "print '%20s %2.2f'%('Iso and Ecross/E',test[isolationvar].corr(test['cluster_ecross_over_e']))\n",
    "print '%20s %2.2f'%('Iso and Ncell',test[isolationvar].corr(test['cluster_ncell']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Correlation between Iso and pt %2.2f'%test['cluster_frixione_its_04_02'].corr(test['cluster_pt'])\n",
    "print 'Correlation between Iso and NN1 %2.2f'%test['cluster_frixione_its_04_02'].corr(test['cluster_NN1'])\n",
    "print 'Correlation between Iso and Lambda %2.2f'%test['cluster_frixione_its_04_02'].corr(test['cluster_Lambda'])\n",
    "\n",
    "\n",
    "print 'Correlation between Iso and ncell %2.2f'%test['cluster_frixione_its_04_02'].corr(test['cluster_ncell'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateFitUncertainty(dataiso, signalmc, datanoniso, binEdges, puritymin, puritymax, fitRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vary data with poisson distribution in each bin\n",
    "_ = getFitResults(varyWithinBins(dataiso, 10000), [signalmc], [datanoniso], binEdges,\n",
    "                         pmin=puritymin, pmax=puritymax, verbosity=0, showDistributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFitUncertaintyExamples(dataiso, dataisoerr, signalmc, datanoniso, binEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closureResults = checkClosureOverParameters(dataiso, signalmc, datanoniso, binEdges, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCheckClosureResults(*closureResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check effect of binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBinEffects(dataHists, mcHists, var, puritymin, puritymax, title,isocut, nonisocuts,isovar, fitRange=None, \n",
    "                    varRange=(0.0, 1.0)):\n",
    "    dataisos, dataisoerrs = [], []\n",
    "    signalmcs, signalmcerrs = [], []\n",
    "    datanonisos, datanonisoerrs = [], []\n",
    "    binEdgess = []        \n",
    "    bins, fracs, fracerrs, purs = [], [], [], []\n",
    "    reduced_chi2= []\n",
    "    \n",
    "    for nBins in range(20, 201,4):\n",
    "        #dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = getTemplates(dataHists, mcHists, nBins,\n",
    "        #var=var)\n",
    "        \n",
    "        #tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, \n",
    "        #                 datanonisoerr, binEdges, verbosity=0, fitRange=fitRange)\n",
    "        \n",
    "        Templates = getTemplates(dataHists, mcHists, nBins,  isocut=isomax, nonisocuts=nonisorange, \n",
    "                                 var = var,  varRange=varRange, isovar=isolation)\n",
    "        dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges = Templates\n",
    "        tf = TemplateFit(dataiso, dataisoerr, signalmc, signalmcerr, datanoniso, datanonisoerr, binEdges, verbosity=0, fitRange=fitRange)\n",
    "        bins.append(nBins)\n",
    "        fracs.append(tf.fitNsig)\n",
    "        fracerrs.append(tf.fitNsigerr)\n",
    "        purs.append(tf.getPurity(puritymin, puritymax)[0])\n",
    "        reduced_chi2.append(tf.chi2/tf.dof)\n",
    "        if (nBins%10 == 0 and nBins <= 100):\n",
    "            dataisos.append(dataiso)\n",
    "            dataisoerrs.append(dataisoerr)\n",
    "            signalmcs.append(signalmc)\n",
    "            signalmcerrs.append(signalmcerr)\n",
    "            datanonisos.append(datanoniso)\n",
    "            datanonisoerrs.append(datanonisoerr)\n",
    "            binEdgess.append(binEdges)\n",
    "            \n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    #plt.errorbar(bins, fracs, fracerrs, fmt='ko', label='Fit signal fraction')\n",
    "    plt.plot(bins, fracs,  'o', label='Fit signal fraction')\n",
    "\n",
    "    plt.plot(bins, purs, 'bd', label='Purity')\n",
    "    plt.xlabel('Number of bins',fontsize=15)\n",
    "    plt.ylim([0.0, 0.5])\n",
    "    plt.legend(loc='best', fontsize=15, numpoints=1)\n",
    "    plt.title(title,fontsize=15)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('Binning_purity_%s.pdf'%title) \n",
    "\n",
    "    ax = plt.gca()\n",
    "    #ax.axhspan(np.mean(purs)-0.02, np.mean(purs)+0.02, color='green', alpha=0.2)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(bins, reduced_chi2,'-o')\n",
    "    plt.ylabel(r'$\\chi^{2}$/dof', fontsize=15)\n",
    "    plt.xlabel('Number of bins',fontsize=15)\n",
    "    plt.ylim(ymin=0.0)\n",
    "    plt.title(title,fontsize=15)\n",
    "    plt.legend(loc='best', fontsize=15, numpoints=1)\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('Binning_chi2_%s.pdf'%title) \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "isomax=1.0\n",
    "nonisorange=(3,10)\n",
    "isolationvar = 'cluster_iso_its_04_sub'\n",
    "\n",
    "\n",
    "checkBinEffects(dataHists, mcSignal_Hists, 'cluster_NN1', 0.5, 0.85, 'DNN',  varRange=(0,1.0), isocut=isomax, \n",
    "                nonisocuts=nonisorange, isovar=isolationvar, fitRange= (0.05, 0.88))\n",
    "\n",
    "checkBinEffects(dataHists, mcSignal_Hists, 'cluster_Lambda', 0.0, 0.40, 'Lambda',  varRange=(0,2.0), isocut=isomax, \n",
    "                nonisocuts=nonisorange, isovar=isolationvar, fitRange=(0.0, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkBinEffects(dataHists, mcHists, 'cluster_Lambda', 0.0, 0.40, '$\\lambda$', None, varRange=(0.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.sample(range(10), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.hist(dataHists['cluster_iso_its_04'], range=(-5,25), bins=30,label='Cone_its',histtype='step')\n",
    "plt.hist(dataHists['cluster_iso_its_04_sub'], range=(-5,25), bins=30,label='cluster_frixione_its_04_02',histtype='step')\n",
    "#plt.axvline(x=2.0, color='r')\n",
    "#plt.axvline(x=5.0, color='g')\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('cluster track-isolation [GeV]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.hist(dataHists['ue_estimate_its_const'], range=(0,10), bins=100,label='Data',histtype='step',density=True)\n",
    "plt.hist(mcBKG_Hists[\"ue_estimate_its_const\"], range=(0,10), bins=100, label='MC', histtype='step',density=True)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('rho (GeV)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE ISO AND NON-ISO REGIONS IN MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 25\n",
    "fig = plt.figure(figsize=(18,6))#fig = plt.figure()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "\n",
    "MCtest = mcBKG_Hists.query('cluster_pt<20 and cluster_pt>12 and cluster_iso_04_truth>1')\n",
    "\n",
    "nonisorange = 'cluster_iso_its_04_sub>5.0 and cluster_iso_its_04_sub<10.0 '\n",
    "isorange    = 'cluster_iso_its_04_sub<1.5 '\n",
    "\n",
    "plt.hist(MCtest.query(nonisorange)['cluster_NN1'],range=(0,1.0), \n",
    "         bins=nbins, density=True, label='5<Iso<10 GeV/c',alpha=0.5,  weights=MCtest.query(nonisorange)['weights'])\n",
    "plt.hist(MCtest.query(isorange)['cluster_NN1'],range=(0,1.0), \n",
    "         bins=nbins, density=True,label= 'Iso<1.5 GeV/c',alpha=0.5, weights=MCtest.query(isorange)['weights'])\n",
    "#plt.legend(loc='best', fontsize=14)\n",
    "\n",
    "plt.xlabel('Deep Neural Network', fontsize=20)\n",
    "plt.ylabel('normalized counts ', fontsize=20)\n",
    "\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "\n",
    "plt.hist(mcBKG_Hists.query(nonisorange)['cluster_Lambda'],range=(0,1.8), \n",
    "         bins=nbins, density=True, label='MC 5<Iso<10 GeV/c',alpha=0.5, weights=MCtest.query(nonisorange)['weights'])\n",
    "\n",
    "plt.hist(mcBKG_Hists.query(isorange)['cluster_Lambda'],range=(0,1.8), \n",
    "         bins=nbins, density=True,label= 'MC Iso<1.5 GeV/c',alpha=0.5,weights=MCtest.query(isorange)['weights'])\n",
    "plt.legend(loc='best', fontsize=14)\n",
    "\n",
    "plt.xlabel(r'$\\sigma_{long}^{2}$', fontsize=20)\n",
    "plt.ylabel('normalized counts ', fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "\n",
    "plt.hist(mcBKG_Hists.query(nonisorange)['cluster_emax_over_e'],range=(0,1.0), \n",
    "         bins=nbins, density=True, label='MC 5<Iso<10 GeV/c',alpha=0.5, weights=MCtest.query(nonisorange)['weights'])\n",
    "\n",
    "plt.hist(mcBKG_Hists.query(isorange)['cluster_emax_over_e'],range=(0,1.0), \n",
    "         bins=nbins, density=True,label= 'MC Iso<1.5 GeV/c',alpha=0.5,weights=MCtest.query(isorange)['weights'])\n",
    "#plt.legend(loc='best', fontsize=14)\n",
    "\n",
    "plt.xlabel(r'$E_{max}/E_{cluster}$', fontsize=20)\n",
    "plt.ylabel('normalized counts ', fontsize=20)\n",
    "\n",
    "plt.title('Dijet MC,'+r' 12 < $p_{T}$ < 30 GeV/c',fontsize=20)\n",
    "\n",
    "\n",
    "   # plt.hist(test.query(mask)['cluster_emax_over_e'], range=(0,1.0), linewidth=1.0,bins=nbins,label=tag,normed=True,alpha=0.8,histtype='step')\n",
    " #   plt.xlabel(r'$E_{max}/E_{cluster}$', fontsize=20)\n",
    "  #  plt.ylabel('counts ', fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('ShowerShape_DijetStudy%s.pdf'%mcBKG_Files[0].split('.root')[0])\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(mcBKG_Hists['cluster_iso_04_truth'], range=(-5,20),  weights=mcBKG_Hists['weights'],bins=100,label='truth',histtype='step')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('cluster isolation truth [GeV]')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbinsDNN = 100\n",
    "fig = plt.figure(figsize=(18,6 ))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.hist(mcBKG_Hists['cluster_iso_04_truth'], range=(0,50),  weights=mcBKG_Hists['weights'],bins=100,label='bkg truth',histtype='step')\n",
    "plt.hist(mcBKG_Hists['cluster_iso_its_04'], range=(-5,50), weights=mcBKG_Hists['weights'], bins=100,label='bkg reco',histtype='step')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(mcSignal_Hists['cluster_iso_04_truth'], range=(0,50),  weights=mcSignal_Hists['weights'],bins=100,label='signal truth',histtype='step')\n",
    "plt.hist(mcSignal_Hists['cluster_iso_its_04'], range=(-5,50), weights=mcSignal_Hists['weights'], bins=100,label='signal reco',histtype='step')\n",
    "\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('cluster track-isolation [GeV]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "647px",
    "left": "0px",
    "right": "1708px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
